{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0eb7b6a",
   "metadata": {},
   "source": [
    "# Rapport data challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bdea69",
   "metadata": {},
   "source": [
    "## Résumé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e256e74",
   "metadata": {},
   "source": [
    "Pour obtenir un F1-score optimal, les paramètres suivants ont été utilisés :\n",
    "* Classifieur **SVM avec kernel Tanimoto**, paramètre de régularisation **C=6**\n",
    "* 7 feature extractors\n",
    "  1) Parameter-Free Threshold Adjacency Statistics\n",
    "  2) Statistiques des canaux de couleur (moyenne, écart-type, asymétrie, kurtosis)\n",
    "  3) Hu Moments\n",
    "  4) Features de texture Haralick (distance=2, moyenne Point-to-Point et 14 features calculées)\n",
    "  5) Histogramme de couleurs avec 11 bins\n",
    "  6) Local Binary Patterning, avec un rayon de 9 pixels et 72 points\n",
    "  7) Descripteurs SIFT, clusterisés avec 300 centroides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a49d1",
   "metadata": {},
   "source": [
    "## Import des librairies et des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4c7d300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, LeaveOneOut\n",
    "from scipy.stats import skew, kurtosis\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mahotas\n",
    "from mahotas.features import surf\n",
    "from skimage.feature import local_binary_pattern\n",
    "import umap.umap_ as umap\n",
    "import pykernels\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a5ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\"F\":1, \"DC\":2, \"PC\":3, \"PT\":4, \"MC\":5, \"LC\":6, \"A\":7, \"TA\":8}\n",
    "# Liste contenant le nom des fichiers de Train\n",
    "files_train = [f\"data-challenge/Train/{f}\" for f in os.listdir(path=\"data-challenge/Train/\")]\n",
    "# Liste contenant le nom des fichiers de Test\n",
    "files_test = [f\"data-challenge/Test/SOB_{i}.png\" for i in range(1, 208)]\n",
    "y_train = np.array([int(class_mapping[f.split(\"_\")[2].split(\"-\")[0]]) for f in files_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9937879b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label, count = np.unique(y_train, return_counts=True)\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "bars = ax.bar(label, count, width=0.6)\n",
    "ax.bar_label(bars)\n",
    "ax.set_xlabel(\"Classe\")\n",
    "ax.set_ylabel(\"Nombre d'observations\")\n",
    "ax.set_title(\"Nombre d'observations par classe\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e425ac",
   "metadata": {},
   "source": [
    "On observe que le jeu d'entraînement est déséquilibré, les classes 6 et 8 sont sous-représentées. Le nombre minimal d'observations dans une classe est de 16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7b6169",
   "metadata": {},
   "source": [
    "## Méthodologie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19697eb1",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;D'après l'état de l'art, les meilleurs résultats pour la classification d'images histopathologiques de tumeurs du sein sont tous obtenus avec des réseaux de neurones convolutionnels. Cependant, notre jeu de données ne contient que 422 images d'entraînement, ce qui à première vue semble insuffisant pour entraîner un réseau de neurones performant. J'ai donc préféré adopter une approche basée sur du feature engineering avec un classifieur basé sur du machine learning classique. <br>\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;Je me suis inspiré des méthodes décrites dans l'introduction de l'article suivant (https://arxiv.org/pdf/1811.04241.pdf) pour sélectionner les features les plus intéressantes à tester en priorité : <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Before the deep learning revolution, machine learning approaches including the\n",
    "Support Vector Machine (SVM), Principle Component Analysis (PCA), and Random Forest (RF) were used to study\n",
    "data whose features were extracted with **Scale Invariant Feature Extraction (SIFT)**, **Local Binary Patterning (LBP)**, **Local Phase Quantization (LPQ)**, the **Gray-Level Co-occurrence Matrix (GLCM)**, **Threshold Adjacency Statistics (TAS)**, and **Parameter Free TAS (PFTAS)**. In 2016, one of the very popular databases for BC classification problem was released, and one research group reported approximately 85.1% accuracy utilizing SVM and PFTAS features for patient-level analysis, which was the highest recognition accuracy at the time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba0c61",
   "metadata": {},
   "source": [
    "Ma démarche de création de classifieur optimal peut se résumer en 3 étapes principales :\n",
    "1) <u>Sélection d'un classifieur </u>: Parmi les différentes méthodes d'extraction citées ci-dessus, certaines ne nécessitent peu ou pas de configuration pour générer des features (PFTAS, Haralick, Hu Moments). J'ai donc commencé par tester différents classifieurs sur les features extraites avec ces méthodes pour sélectionner un seul classifieur plus performant. <br>\n",
    "2) <u> Optimisation de features pour le classifieur retenu</u>: D'autres méthodes d'extraction se basent sur des features locales, ou ont besoin de plus de paramètres pour être configurées (Histogramme de couleurs, LBP, SIFT). J'ai donc configuré ces méthodes d'extraction pour fournir unitairement le score le plus élevé avec le classifieur retenu à l'étape 1.<br>\n",
    "3) <u>Optimisation de la combinaison des features </u>: Enfin, après combinaison des features, j'ai réoptimisé la configuration de la génération des features pour obtenir le meilleur score possible avec l'ensemble des features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5a3845",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;Pour ce qui est de la méthodologie de test, le jeu d'entraînement ne comporte que 422 images. **Il se prête donc assez mal à un découpage `train_test_split` classique**. Le jeu d'entraînement étant petit, il est improbable qu'il contienne toute la variance de chaque classe. Diminuer ce jeu d'entraînement pour réaliser un jeu unique de cross validation semble donc une mauvaise idée, car il risque de créer de l'overfitting sur le jeu de cross validation ainsi créé, et de l'underfitting global sur la distribution des images. <br>\n",
    "&nbsp;&nbsp;**J'ai donc préféré utiliser la méthode `cross_val_score` de scikit-learn** pour tester les hyperparamètres de mes différents modèles, et comparer les modèles entre eux. L'évaluation du data-challenge étant basée sur le F1-Score `\"weigthed\"`, je n'ai utilisé `cross_val_score` qu'avec le paramètre `scoring=\"f1_weighted\"`, et conservé la moyenne des scores obtenus sur chaque fold comme métrique. Le jeu d'entraînement étant petit, un nombre de folds important permet de maximiser l'information apprise par chaque modèle, et de réduire la variance entre les scores obtenus sur chaque fold. J'ai donc maximisé le paramètre `cv` lors de l'entraînement. Dans notre cas, le maximum attribuable à `cv` est 16, car c'est le nombre d'observations que contient la classe la moins représentée (classes 6 et 8). <br>\n",
    "&nbsp;&nbsp;Dans la dernière étape, j'ai **utilisé la méthode de cross-validation `Leave-One-Out`** fournie par scikit-learn. Cette méthode permet d'avoir une évaluation plus robuste des performances du modèle testé, et donc d'avoir une évaluation plus précise du modèle avant utilisation sur le jeu de test. Cependant, elle est également plus calculatoire (421 fits réalisés pour chaque test), et l'utiliser dès le début aurait été très long coûteux à une étape ne nécessitant pas encore d'optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d423e769",
   "metadata": {},
   "source": [
    "## Sélection d'un classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3cbb6e",
   "metadata": {},
   "source": [
    "Les différents classifieurs testés ont été les suivants:\n",
    "* SVM\n",
    "* Random Forest\n",
    "* Gradient Boosting\n",
    "* K-Nearest Neighbors\n",
    "* LDA\n",
    "\n",
    "RandomForest et GradientBoosting ont un grand nombre d'hyperparamètres, qui nécessitent d'être combinés pour aboutir à une augmentation importante du score. Ces modèles ont donc été testés avec des paramètres de bases, et leurs hyperparamètres optimisés uniquement si les scores qu'ils fournissent semblent le justifier. <br>\n",
    "Différents tests ont également été réalisés avec PCA, afin de réduire la dimension des features avant classification. Les résultats n'étaient pas concluants, et n'ont donc pas été inclus dans ce rapport pour ne pas l'alourdir (les méthodes avec kernel fonctionnent très bien avec un grand nombre de features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ff4c0",
   "metadata": {},
   "source": [
    "### Parameter-Free Threshold Adjacency Statistics (PFTAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39f470",
   "metadata": {},
   "source": [
    "Il est possible d'extraire les features PFTAS sur les images en noir et blanc, ce qui génère 54 features au lieu de 162. Les différents classifieurs ont été testés sur ces 54 features, mais obtenaient de manière unanime des scores moins bon qu'avec les 162 features extraites sur les images couleurs. Pour ne pas alourdir davantage ce rapport, ces résultats n'ont pas été intégrés à ce rapport. Par la suite, lorsqu'un extracteur de feature fonctionne sur des images couleur, il a toujours été utilisé sur les images couleur pour maximiser les informations disponibles. <br>\n",
    "PFTAS est une feature d'image globale, qui ne nécessite pas de configuration particulière lors de l'utilisation de l'API Mahotas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d606d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((422, 162), (207, 162))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pftas = np.array([mahotas.features.pftas(np.array(Image.open(f))) for f in files_train])\n",
    "pftas_test = np.array([mahotas.features.pftas(np.array(Image.open(f))) for f in files_test])\n",
    "pftas.shape, pftas_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e826b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pftas_scaled = scaler.fit_transform(pftas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c0c9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ab8c462674452d860667f98984eadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for SVM is 0.8209024919762099 for C = 17\n"
     ]
    }
   ],
   "source": [
    "reg = range(1, 101)\n",
    "score = []\n",
    "for c in tqdm(reg):\n",
    "    svm = SVC(C=c)\n",
    "    score.append(np.mean(cross_val_score(svm, pftas_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score for SVM is {np.max(score)} for C = {np.argmax(score) + 1}\")\n",
    "score_svm = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d83ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Random Forest is 0.7732068481534293.\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "score_rfc = np.mean(cross_val_score(rfc, pftas, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Random Forest is {score_rfc}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b324324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Gradient Boosting is 0.7514329252577117.\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "score_gboost = np.mean(cross_val_score(gboost, pftas, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Gradient Boosting is {score_gboost}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a207515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dda4c4b89a43049811854fa40267af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for KNN is 0.7631828834152552 for k = 1\n"
     ]
    }
   ],
   "source": [
    "neigh = range(1, 101)\n",
    "score = []\n",
    "for k in tqdm(neigh):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score.append(np.mean(cross_val_score(knn, pftas_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score for KNN is {np.max(score)} for k = {np.argmax(score) + 1}\")\n",
    "score_knn = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfd5ff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LDA classifier is 0.7229427391419913.\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "score_lda = np.mean(cross_val_score(lda, pftas, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for LDA classifier is {score_lda}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22e722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LDA classifier is 0.7664051182080028.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "score_lr = np.mean(cross_val_score(lr, pftas_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Logistic Regression classifier is {score_lr}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f80db3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature  </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS    </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature  </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS    </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation\")\n",
    "f1_scores = []\n",
    "f1_scores.append([\"PFTAS\", score_svm, score_rfc, score_gboost, score_knn, score_lda, score_lr])\n",
    "tabulate(f1_scores, headers=[\"Feature\", \"SVM\", \"RandomForest\", \"GradientBoosting\", \"KNN\", \"LDA\", \"LogisticRegression\"],\n",
    "         tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70655b0e",
   "metadata": {},
   "source": [
    "### Color channel statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da0a54",
   "metadata": {},
   "source": [
    "Une feature facile à calculer est la moyenne et l'écart-type de chaque canal de couleur. La librairie `scipy` permet également de calculer les moments d'ordre 3 et 4, je les ai donc ajouté aux moyennes et écart-types calculés. <br>\n",
    "Pour chacun des 3 canaux sont donc extraits 4 valeurs (moyenne, écart-type, asymétrie et kurtosis), ce qui revient à créer 12 features par image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "132cb343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((422, 12), (207, 12))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chan_stats = np.array([np.concatenate([np.mean(Image.open(f), axis=(0,1)),\n",
    "                                       np.std(Image.open(f), axis=(0,1)),\n",
    "                                       skew(Image.open(f), axis=(0,1)),\n",
    "                                       kurtosis(Image.open(f), axis=(0,1))]) for f in files_train])\n",
    "chan_stats_test = np.array([np.concatenate([np.mean(Image.open(f), axis=(0,1)),\n",
    "                                       np.std(Image.open(f), axis=(0,1)),\n",
    "                                       skew(Image.open(f), axis=(0,1)),\n",
    "                                       kurtosis(Image.open(f), axis=(0,1))]) for f in files_test])\n",
    "chan_stats.shape, chan_stats_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e147bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "chan_stats_scaled = scaler.fit_transform(chan_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11e545d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ef983b011e4773baea49289affb819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for SVM is 0.822807826867656 for C = 29\n"
     ]
    }
   ],
   "source": [
    "reg = range(1, 101)\n",
    "score = []\n",
    "for c in tqdm(reg):\n",
    "    svm = SVC(C=c)\n",
    "    score.append(np.mean(cross_val_score(svm, chan_stats_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score for SVM is {np.max(score)} for C = {np.argmax(score) + 1}\")\n",
    "score_svm = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37b65386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Random Forest is 0.7136460356278732.\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "score_rfc = np.mean(cross_val_score(rfc, chan_stats, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Random Forest is {score_rfc}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af25e5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Gradient Boosting is 0.6692996170693821.\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "score_gboost = np.mean(cross_val_score(gboost, chan_stats, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Gradient Boosting is {score_gboost}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "200f18a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c492fd1d00f4e43b3f34525e61a4b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for KNN is 0.7619063618796524 for k = 1\n"
     ]
    }
   ],
   "source": [
    "neigh = range(1, 101)\n",
    "score = []\n",
    "for k in tqdm(neigh):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score.append(np.mean(cross_val_score(knn, chan_stats_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score for KNN is {np.max(score)} for k = {np.argmax(score) + 1}\")\n",
    "score_knn = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8ad4492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LDA classifier is 0.51524350777823.\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "score_lda = np.mean(cross_val_score(lda, chan_stats, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for LDA classifier is {score_lda}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84d20c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LDA classifier is 0.5571158408898793.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "score_lr = np.mean(cross_val_score(lr, chan_stats_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Logistic Regression classifier is {score_lr}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58ac50d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature                 </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS                   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\n",
       "<tr><td>Color channel statistics</td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\">    0.714     </td><td style=\"text-align: center;\">      0.669       </td><td style=\"text-align: center;\">0.762</td><td style=\"text-align: center;\">0.515</td><td style=\"text-align: center;\">       0.557        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature                 </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS                   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\\n<tr><td>Color channel statistics</td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\">    0.714     </td><td style=\"text-align: center;\">      0.669       </td><td style=\"text-align: center;\">0.762</td><td style=\"text-align: center;\">0.515</td><td style=\"text-align: center;\">       0.557        </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation\")\n",
    "f1_scores.append([\"Color channel statistics\", score_svm, score_rfc, score_gboost, score_knn, score_lda, score_lr])\n",
    "tabulate(f1_scores, headers=[\"Feature\", \"SVM\", \"RandomForest\", \"GradientBoosting\", \"KNN\", \"LDA\", \"LogisticRegression\"],\n",
    "         tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc80257",
   "metadata": {},
   "source": [
    "### Hu Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf6748",
   "metadata": {},
   "source": [
    "Les Moments de Hu ne peuvent se calculer que sur des images en niveau de gris (d'où la conversion 'L' via PIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f05c71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((422, 7), (207, 7))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moments = [cv2.moments(np.array(Image.open(f).convert('L'))) for f in files_train]\n",
    "moments_test = [cv2.moments(np.array(Image.open(f).convert('L'))) for f in files_test]\n",
    "hu = np.array([cv2.HuMoments(m).T for m in moments])[:,0,:]\n",
    "hu_test = np.array([cv2.HuMoments(m).T for m in moments_test])[:,0,:]\n",
    "hu.shape, hu_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5908344",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hu_scaled = scaler.fit_transform(hu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5670c989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542447dd5fdf4f8988f28a0551d25c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for SVM is 0.27556334606948923 for C = 45\n"
     ]
    }
   ],
   "source": [
    "reg = range(1, 101)\n",
    "score = []\n",
    "for c in tqdm(reg):\n",
    "    svm = SVC(C=c)\n",
    "    score.append(np.mean(cross_val_score(svm, hu_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score for SVM is {np.max(score)} for C = {np.argmax(score) + 1}\")\n",
    "score_svm = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6447b692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Random Forest is 0.14585625181244838.\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "score_rfc = np.mean(cross_val_score(rfc, hu, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Random Forest is {score_rfc}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0b2574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Gradient Boosting is 0.14508764027994797.\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "score_gboost = np.mean(cross_val_score(gboost, hu, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Gradient Boosting is {score_gboost}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "298749a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a923ebfc39fd49d49e559e0b7226244e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for KNN is 0.26239244983514454 for k = 33\n"
     ]
    }
   ],
   "source": [
    "neigh = range(1, 101)\n",
    "score = []\n",
    "for k in tqdm(neigh):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score.append(np.mean(cross_val_score(knn, hu_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score for KNN is {np.max(score)} for k = {np.argmax(score) + 1}\")\n",
    "score_knn = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc45756d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LDA classifier is 0.22647633404414946.\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "score_lda = np.mean(cross_val_score(lda, hu, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for LDA classifier is {score_lda}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc61a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LDA classifier is 0.2473048105489527.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "score_lr = np.mean(cross_val_score(lr, hu_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Logistic Regression classifier is {score_lr}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04e34c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature                 </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS                   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\n",
       "<tr><td>Color channel statistics</td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\">    0.714     </td><td style=\"text-align: center;\">      0.669       </td><td style=\"text-align: center;\">0.762</td><td style=\"text-align: center;\">0.515</td><td style=\"text-align: center;\">       0.557        </td></tr>\n",
       "<tr><td>Hu moments              </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\">    0.146     </td><td style=\"text-align: center;\">      0.145       </td><td style=\"text-align: center;\">0.262</td><td style=\"text-align: center;\">0.226</td><td style=\"text-align: center;\">       0.247        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature                 </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS                   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\\n<tr><td>Color channel statistics</td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\">    0.714     </td><td style=\"text-align: center;\">      0.669       </td><td style=\"text-align: center;\">0.762</td><td style=\"text-align: center;\">0.515</td><td style=\"text-align: center;\">       0.557        </td></tr>\\n<tr><td>Hu moments              </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\">    0.146     </td><td style=\"text-align: center;\">      0.145       </td><td style=\"text-align: center;\">0.262</td><td style=\"text-align: center;\">0.226</td><td style=\"text-align: center;\">       0.247        </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation\")\n",
    "f1_scores.append([\"Hu moments\", score_svm, score_rfc, score_gboost, score_knn, score_lda, score_lr])\n",
    "tabulate(f1_scores, headers=[\"Feature\", \"SVM\", \"RandomForest\", \"GradientBoosting\", \"KNN\", \"LDA\", \"LogisticRegression\"],\n",
    "         tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1c159",
   "metadata": {},
   "source": [
    "Les scores obtenus via Hu Moments semblent vraiment très faibles comparés aux 2 features précédentes. Cependant, après combinaison avec d'autres features, il apparaît que l'utilisation de ces 7 features participe à l'augmentation du score de classification. Elles ont donc été conservées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034ed2f",
   "metadata": {},
   "source": [
    "### Haralick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58562ea4",
   "metadata": {},
   "source": [
    "Haralick permet d'extraire des informations de texture globales sur chaque image. De même que pour PFTAS, son utilisation sur des images en couleur génère des features en plus grande dimension, mais fournissant un score de classification plus élevé. <br>\n",
    "3 paramètres principaux peuvent être configurés sur cette feature via l'API Mahotas :\n",
    "* distance : vaut 1 ou 2. Les tests ci-dessous justifient la configuration de ce paramètre à 2\n",
    "* return_mean : permet de retourner la moyenne selon toutes les directions (return_mean=True) ou la moyenne et ptp (point-to-point = difference entre max() and min()). De manière empirique, il apparaît que return_mean_ptp=True à un fort impact sur le score\n",
    "* compute_14th_feature : permet de calculer une 14ème feature Haralick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fce5fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean=True,\n",
    "                                         compute_14th_feature=False, distance=1) for f in files_train])\n",
    "# Point-to-point (max-min) mean instead of standard mean\n",
    "h2 = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean_ptp=True,\n",
    "                                         compute_14th_feature=False, distance=1) for f in files_train])\n",
    "# With 14th feature and standard mean\n",
    "h3 = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean=True,\n",
    "                                         compute_14th_feature=True, distance=1) for f in files_train])\n",
    "# With 14th feature and point-to-point mean\n",
    "h4 = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean_ptp=True,\n",
    "                                         compute_14th_feature=True, distance=1) for f in files_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a46970e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "h1_scaled = scaler.fit_transform(h1)\n",
    "h2_scaled = scaler.fit_transform(h2)\n",
    "h3_scaled = scaler.fit_transform(h3)\n",
    "h4_scaled = scaler.fit_transform(h4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e19aa658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e40bfec02e44fe9cd260bc3a6f5f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score1 for SVM is 0.6952629047313876 for C = 75\n",
      "Best score2 for SVM is 0.7906809427909856 for C = 36\n",
      "Best score3 for SVM is 0.7347596007585324 for C = 97\n",
      "Best score4 for SVM is 0.7913133627610123 for C = 29\n"
     ]
    }
   ],
   "source": [
    "reg = range(1, 101)\n",
    "score1, score2, score3, score4 = [], [], [], []\n",
    "for c in tqdm(reg):\n",
    "    svm = SVC(C=c)\n",
    "    score1.append(np.mean(cross_val_score(svm, h1_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score2.append(np.mean(cross_val_score(svm, h2_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score3.append(np.mean(cross_val_score(svm, h3_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score4.append(np.mean(cross_val_score(svm, h4_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score1 for SVM is {np.max(score1)} for C = {np.argmax(score1) + 1}\")\n",
    "print(f\"Best score2 for SVM is {np.max(score2)} for C = {np.argmax(score2) + 1}\")\n",
    "print(f\"Best score3 for SVM is {np.max(score3)} for C = {np.argmax(score3) + 1}\")\n",
    "print(f\"Best score4 for SVM is {np.max(score4)} for C = {np.argmax(score4) + 1}\")\n",
    "score_svm1, score_svm2, score_svm3, score_svm4 = np.max(score1), np.max(score2), np.max(score3), np.max(score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36fed9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score1 for Random Forest is 0.6474729305501679.\n",
      "Score2 for Random Forest is 0.6859445926620071.\n",
      "Score3 for Random Forest is 0.6362900715841893.\n",
      "Score4 for Random Forest is 0.705689948010995.\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "score_rfc1 = np.mean(cross_val_score(rfc, h1, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_rfc2 = np.mean(cross_val_score(rfc, h2, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_rfc3 = np.mean(cross_val_score(rfc, h3, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_rfc4 = np.mean(cross_val_score(rfc, h4, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score1 for Random Forest is {score_rfc1}.\")\n",
    "print(f\"Score2 for Random Forest is {score_rfc2}.\")\n",
    "print(f\"Score3 for Random Forest is {score_rfc3}.\")\n",
    "print(f\"Score4 for Random Forest is {score_rfc4}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bad356a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score1 for Gradient Boosting is 0.6044954417417024.\n",
      "Score2 for Gradient Boosting is 0.6718895964355366.\n",
      "Score3 for Gradient Boosting is 0.6286542902438139.\n",
      "Score4 for Gradient Boosting is 0.6776588044750438.\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "score_gboost1 = np.mean(cross_val_score(gboost, h1, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_gboost2 = np.mean(cross_val_score(gboost, h2, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_gboost3 = np.mean(cross_val_score(gboost, h3, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_gboost4 = np.mean(cross_val_score(gboost, h4, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score1 for Gradient Boosting is {score_gboost1}.\")\n",
    "print(f\"Score2 for Gradient Boosting is {score_gboost2}.\")\n",
    "print(f\"Score3 for Gradient Boosting is {score_gboost3}.\")\n",
    "print(f\"Score4 for Gradient Boosting is {score_gboost4}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70748554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ac6b04fe0b450ebcefe7c005e35366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score1 for KNN is 0.6314092147959669 for k = 1\n",
      "Best score2 for KNN is 0.6852483673931323 for k = 1\n",
      "Best score3 for KNN is 0.6907100496844087 for k = 1\n",
      "Best score4 for KNN is 0.6881899222176999 for k = 1\n"
     ]
    }
   ],
   "source": [
    "neigh = range(1, 101)\n",
    "score1, score2, score3, score4 = [], [], [], []\n",
    "for k in tqdm(neigh):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score1.append(np.mean(cross_val_score(knn, h1_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score2.append(np.mean(cross_val_score(knn, h2_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score3.append(np.mean(cross_val_score(knn, h3_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score4.append(np.mean(cross_val_score(knn, h4_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score1 for KNN is {np.max(score1)} for k = {np.argmax(score1) + 1}\")\n",
    "print(f\"Best score2 for KNN is {np.max(score2)} for k = {np.argmax(score2) + 1}\")\n",
    "print(f\"Best score3 for KNN is {np.max(score3)} for k = {np.argmax(score3) + 1}\")\n",
    "print(f\"Best score4 for KNN is {np.max(score4)} for k = {np.argmax(score4) + 1}\")\n",
    "score_knn1, score_knn2, score_knn3, score_knn4 = np.max(score1), np.max(score2), np.max(score3), np.max(score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47169279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score1 for LDA classifier is 0.493581788186489.\n",
      "Score2 for LDA classifier is 0.5706925355429628.\n",
      "Score3 for LDA classifier is 0.49927218189771605.\n",
      "Score4 for LDA classifier is 0.6044778986678183.\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "score_lda1 = np.mean(cross_val_score(lda, h1, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lda2 = np.mean(cross_val_score(lda, h2, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lda3 = np.mean(cross_val_score(lda, h3, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lda4 = np.mean(cross_val_score(lda, h4, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score1 for LDA classifier is {score_lda1}.\")\n",
    "print(f\"Score2 for LDA classifier is {score_lda2}.\")\n",
    "print(f\"Score3 for LDA classifier is {score_lda3}.\")\n",
    "print(f\"Score4 for LDA classifier is {score_lda4}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28b0bd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score1 for LDA classifier is 0.49613273024063625.\n",
      "Score2 for LDA classifier is 0.5831190656644717.\n",
      "Score3 for LDA classifier is 0.5115992803492804.\n",
      "Score4 for LDA classifier is 0.63381968913486.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "score_lr1 = np.mean(cross_val_score(lr, h1_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lr2 = np.mean(cross_val_score(lr, h2_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lr3 = np.mean(cross_val_score(lr, h3_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lr4 = np.mean(cross_val_score(lr, h4_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score1 for Logistic Regression classifier is {score_lr1}.\")\n",
    "print(f\"Score2 for Logistic Regression classifier is {score_lr2}.\")\n",
    "print(f\"Score3 for Logistic Regression classifier is {score_lr3}.\")\n",
    "print(f\"Score4 for Logistic Regression classifier is {score_lr4}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f64f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Même distinctions que précédemment, mais avec distance = 2\n",
    "h5 = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean=True,\n",
    "                                         compute_14th_feature=False, distance=2) for f in files_train])\n",
    "h6 = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean_ptp=True,\n",
    "                                         compute_14th_feature=False, distance=2) for f in files_train])\n",
    "h7 = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean=True,\n",
    "                                         compute_14th_feature=True, distance=2) for f in files_train])\n",
    "h8 = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean_ptp=True,\n",
    "                                         compute_14th_feature=True, distance=2) for f in files_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "202f9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_scaled = scaler.fit_transform(h5)\n",
    "h6_scaled = scaler.fit_transform(h6)\n",
    "h7_scaled = scaler.fit_transform(h7)\n",
    "h8_scaled = scaler.fit_transform(h8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d29478a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15cd0e32f5d46a8a4ee668837aa7f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score5 for SVM is 0.7079736107513885 for C = 50\n",
      "Best score6 for SVM is 0.8292563996623825 for C = 31\n",
      "Best score7 for SVM is 0.7061796050578102 for C = 37\n",
      "Best score8 for SVM is 0.8333612385161531 for C = 38\n"
     ]
    }
   ],
   "source": [
    "reg = range(1, 101)\n",
    "score5, score6, score7, score8 = [], [], [], []\n",
    "for c in tqdm(reg):\n",
    "    svm = SVC(C=c)\n",
    "    score5.append(np.mean(cross_val_score(svm, h5_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score6.append(np.mean(cross_val_score(svm, h6_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score7.append(np.mean(cross_val_score(svm, h7_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score8.append(np.mean(cross_val_score(svm, h8_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score5 for SVM is {np.max(score5)} for C = {np.argmax(score5) + 1}\")\n",
    "print(f\"Best score6 for SVM is {np.max(score6)} for C = {np.argmax(score6) + 1}\")\n",
    "print(f\"Best score7 for SVM is {np.max(score7)} for C = {np.argmax(score7) + 1}\")\n",
    "print(f\"Best score8 for SVM is {np.max(score8)} for C = {np.argmax(score8) + 1}\")\n",
    "score_svm5, score_svm6, score_svm7, score_svm8 = np.max(score5), np.max(score6), np.max(score7), np.max(score8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da4f7a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score5 for Random Forest is 0.5541581914445162.\n",
      "Score6 for Random Forest is 0.6936840279655451.\n",
      "Score7 for Random Forest is 0.5667967854399478.\n",
      "Score8 for Random Forest is 0.7146535578025963.\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "score_rfc5 = np.mean(cross_val_score(rfc, h5, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_rfc6 = np.mean(cross_val_score(rfc, h6, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_rfc7 = np.mean(cross_val_score(rfc, h7, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_rfc8 = np.mean(cross_val_score(rfc, h8, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score5 for Random Forest is {score_rfc5}.\")\n",
    "print(f\"Score6 for Random Forest is {score_rfc6}.\")\n",
    "print(f\"Score7 for Random Forest is {score_rfc7}.\")\n",
    "print(f\"Score8 for Random Forest is {score_rfc8}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef66da88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score5 for Gradient Boosting is 0.5363362337053577.\n",
      "Score6 for Gradient Boosting is 0.6529655277652072.\n",
      "Score7 for Gradient Boosting is 0.5526022721936183.\n",
      "Score8 for Gradient Boosting is 0.6822285868006079.\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "score_gboost5 = np.mean(cross_val_score(gboost, h5, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_gboost6 = np.mean(cross_val_score(gboost, h6, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_gboost7 = np.mean(cross_val_score(gboost, h7, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_gboost8 = np.mean(cross_val_score(gboost, h8, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score5 for Gradient Boosting is {score_gboost5}.\")\n",
    "print(f\"Score6 for Gradient Boosting is {score_gboost6}.\")\n",
    "print(f\"Score7 for Gradient Boosting is {score_gboost7}.\")\n",
    "print(f\"Score8 for Gradient Boosting is {score_gboost8}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1eca6065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6778b890d69e4f89929ba6c529b45d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score5 for KNN is 0.5663647101948384 for k = 1\n",
      "Best score6 for KNN is 0.744069426735025 for k = 1\n",
      "Best score7 for KNN is 0.5750675670681011 for k = 1\n",
      "Best score8 for KNN is 0.7542345949397231 for k = 1\n"
     ]
    }
   ],
   "source": [
    "neigh = range(1, 101)\n",
    "score5, score6, score7, score8 = [], [], [], []\n",
    "for k in tqdm(neigh):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score5.append(np.mean(cross_val_score(knn, h5_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score6.append(np.mean(cross_val_score(knn, h6_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score7.append(np.mean(cross_val_score(knn, h7_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    score8.append(np.mean(cross_val_score(knn, h8_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score5 for KNN is {np.max(score5)} for k = {np.argmax(score5) + 1}\")\n",
    "print(f\"Best score6 for KNN is {np.max(score6)} for k = {np.argmax(score6) + 1}\")\n",
    "print(f\"Best score7 for KNN is {np.max(score7)} for k = {np.argmax(score7) + 1}\")\n",
    "print(f\"Best score8 for KNN is {np.max(score8)} for k = {np.argmax(score8) + 1}\")\n",
    "score_knn5, score_knn6, score_knn7, score_knn8 = np.max(score5), np.max(score6), np.max(score7), np.max(score8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c016112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score5 for LDA classifier is 0.45892584484999016.\n",
      "Score6 for LDA classifier is 0.582648725976089.\n",
      "Score7 for LDA classifier is 0.4729763771563985.\n",
      "Score8 for LDA classifier is 0.6121139771513703.\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "score_lda5 = np.mean(cross_val_score(lda, h5, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lda6 = np.mean(cross_val_score(lda, h6, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lda7 = np.mean(cross_val_score(lda, h7, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lda8 = np.mean(cross_val_score(lda, h8, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score5 for LDA classifier is {score_lda5}.\")\n",
    "print(f\"Score6 for LDA classifier is {score_lda6}.\")\n",
    "print(f\"Score7 for LDA classifier is {score_lda7}.\")\n",
    "print(f\"Score8 for LDA classifier is {score_lda8}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "215cab5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score5 for LDA classifier is 0.4777980680090723.\n",
      "Score6 for LDA classifier is 0.6023711627878294.\n",
      "Score7 for LDA classifier is 0.5176363108034173.\n",
      "Score8 for LDA classifier is 0.6242717575029666.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "score_lr5 = np.mean(cross_val_score(lr, h5_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lr6 = np.mean(cross_val_score(lr, h6_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lr7 = np.mean(cross_val_score(lr, h7_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "score_lr8 = np.mean(cross_val_score(lr, h8_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score5 for Logistic Regression classifier is {score_lr5}.\")\n",
    "print(f\"Score6 for Logistic Regression classifier is {score_lr6}.\")\n",
    "print(f\"Score7 for Logistic Regression classifier is {score_lr7}.\")\n",
    "print(f\"Score8 for Logistic Regression classifier is {score_lr8}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8dc7a9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation des paramètres Haralick\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Paramètres Haralick      </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Dist 1, mean, 13 feat    </td><td style=\"text-align: center;\">0.695</td><td style=\"text-align: center;\">    0.647     </td><td style=\"text-align: center;\">      0.604       </td><td style=\"text-align: center;\">0.631</td><td style=\"text-align: center;\">0.494</td><td style=\"text-align: center;\">       0.496        </td></tr>\n",
       "<tr><td>Dist 1, ptp mean, 13 feat</td><td style=\"text-align: center;\">0.791</td><td style=\"text-align: center;\">    0.686     </td><td style=\"text-align: center;\">      0.672       </td><td style=\"text-align: center;\">0.685</td><td style=\"text-align: center;\">0.571</td><td style=\"text-align: center;\">       0.583        </td></tr>\n",
       "<tr><td>Dist 1, mean, 14 feat    </td><td style=\"text-align: center;\">0.735</td><td style=\"text-align: center;\">    0.636     </td><td style=\"text-align: center;\">      0.629       </td><td style=\"text-align: center;\">0.691</td><td style=\"text-align: center;\">0.499</td><td style=\"text-align: center;\">       0.512        </td></tr>\n",
       "<tr><td>Dist 1, ptp mean, 14 feat</td><td style=\"text-align: center;\">0.791</td><td style=\"text-align: center;\">    0.706     </td><td style=\"text-align: center;\">      0.678       </td><td style=\"text-align: center;\">0.688</td><td style=\"text-align: center;\">0.604</td><td style=\"text-align: center;\">       0.634        </td></tr>\n",
       "<tr><td>Dist 2, mean, 13 feat    </td><td style=\"text-align: center;\">0.708</td><td style=\"text-align: center;\">    0.554     </td><td style=\"text-align: center;\">      0.536       </td><td style=\"text-align: center;\">0.566</td><td style=\"text-align: center;\">0.459</td><td style=\"text-align: center;\">       0.478        </td></tr>\n",
       "<tr><td>Dist 2, ptp mean, 13 feat</td><td style=\"text-align: center;\">0.829</td><td style=\"text-align: center;\">    0.694     </td><td style=\"text-align: center;\">      0.653       </td><td style=\"text-align: center;\">0.744</td><td style=\"text-align: center;\">0.583</td><td style=\"text-align: center;\">       0.602        </td></tr>\n",
       "<tr><td>Dist 2, mean, 14 feat    </td><td style=\"text-align: center;\">0.706</td><td style=\"text-align: center;\">    0.567     </td><td style=\"text-align: center;\">      0.553       </td><td style=\"text-align: center;\">0.575</td><td style=\"text-align: center;\">0.473</td><td style=\"text-align: center;\">       0.518        </td></tr>\n",
       "<tr><td>Dist 2, ptp mean, 14 feat</td><td style=\"text-align: center;\">0.833</td><td style=\"text-align: center;\">    0.715     </td><td style=\"text-align: center;\">      0.682       </td><td style=\"text-align: center;\">0.754</td><td style=\"text-align: center;\">0.612</td><td style=\"text-align: center;\">       0.624        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Paramètres Haralick      </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>Dist 1, mean, 13 feat    </td><td style=\"text-align: center;\">0.695</td><td style=\"text-align: center;\">    0.647     </td><td style=\"text-align: center;\">      0.604       </td><td style=\"text-align: center;\">0.631</td><td style=\"text-align: center;\">0.494</td><td style=\"text-align: center;\">       0.496        </td></tr>\\n<tr><td>Dist 1, ptp mean, 13 feat</td><td style=\"text-align: center;\">0.791</td><td style=\"text-align: center;\">    0.686     </td><td style=\"text-align: center;\">      0.672       </td><td style=\"text-align: center;\">0.685</td><td style=\"text-align: center;\">0.571</td><td style=\"text-align: center;\">       0.583        </td></tr>\\n<tr><td>Dist 1, mean, 14 feat    </td><td style=\"text-align: center;\">0.735</td><td style=\"text-align: center;\">    0.636     </td><td style=\"text-align: center;\">      0.629       </td><td style=\"text-align: center;\">0.691</td><td style=\"text-align: center;\">0.499</td><td style=\"text-align: center;\">       0.512        </td></tr>\\n<tr><td>Dist 1, ptp mean, 14 feat</td><td style=\"text-align: center;\">0.791</td><td style=\"text-align: center;\">    0.706     </td><td style=\"text-align: center;\">      0.678       </td><td style=\"text-align: center;\">0.688</td><td style=\"text-align: center;\">0.604</td><td style=\"text-align: center;\">       0.634        </td></tr>\\n<tr><td>Dist 2, mean, 13 feat    </td><td style=\"text-align: center;\">0.708</td><td style=\"text-align: center;\">    0.554     </td><td style=\"text-align: center;\">      0.536       </td><td style=\"text-align: center;\">0.566</td><td style=\"text-align: center;\">0.459</td><td style=\"text-align: center;\">       0.478        </td></tr>\\n<tr><td>Dist 2, ptp mean, 13 feat</td><td style=\"text-align: center;\">0.829</td><td style=\"text-align: center;\">    0.694     </td><td style=\"text-align: center;\">      0.653       </td><td style=\"text-align: center;\">0.744</td><td style=\"text-align: center;\">0.583</td><td style=\"text-align: center;\">       0.602        </td></tr>\\n<tr><td>Dist 2, mean, 14 feat    </td><td style=\"text-align: center;\">0.706</td><td style=\"text-align: center;\">    0.567     </td><td style=\"text-align: center;\">      0.553       </td><td style=\"text-align: center;\">0.575</td><td style=\"text-align: center;\">0.473</td><td style=\"text-align: center;\">       0.518        </td></tr>\\n<tr><td>Dist 2, ptp mean, 14 feat</td><td style=\"text-align: center;\">0.833</td><td style=\"text-align: center;\">    0.715     </td><td style=\"text-align: center;\">      0.682       </td><td style=\"text-align: center;\">0.754</td><td style=\"text-align: center;\">0.612</td><td style=\"text-align: center;\">       0.624        </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluation des paramètres Haralick\")\n",
    "f1_params = []\n",
    "f1_params.append([\"Dist 1, mean, 13 feat\", score_svm1, score_rfc1, score_gboost1, score_knn1, score_lda1, score_lr1])\n",
    "f1_params.append([\"Dist 1, ptp mean, 13 feat\", score_svm2, score_rfc2, score_gboost2, score_knn2, score_lda2, score_lr2])\n",
    "f1_params.append([\"Dist 1, mean, 14 feat\", score_svm3, score_rfc3, score_gboost3, score_knn3, score_lda3, score_lr3])\n",
    "f1_params.append([\"Dist 1, ptp mean, 14 feat\", score_svm4, score_rfc4, score_gboost4, score_knn4, score_lda4, score_lr4])\n",
    "f1_params.append([\"Dist 2, mean, 13 feat\", score_svm5, score_rfc5, score_gboost5, score_knn5, score_lda5, score_lr5])\n",
    "f1_params.append([\"Dist 2, ptp mean, 13 feat\", score_svm6, score_rfc6, score_gboost6, score_knn6, score_lda6, score_lr6])\n",
    "f1_params.append([\"Dist 2, mean, 14 feat\", score_svm7, score_rfc7, score_gboost7, score_knn7, score_lda7, score_lr7])\n",
    "f1_params.append([\"Dist 2, ptp mean, 14 feat\", score_svm8, score_rfc8, score_gboost8, score_knn8, score_lda8, score_lr8])\n",
    "tabulate(f1_params, headers=[\"Paramètres Haralick\", \"SVM\", \"RandomForest\", \"GradientBoosting\", \"KNN\", \"LDA\", \"LogisticRegression\"],\n",
    "         tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c41c1",
   "metadata": {},
   "source": [
    "Le meilleur score pour chaque classifieur (sauf Logisitc Regression, mais l'écart n'est pas très important) est atteint avec une distance de 2, une moyenne Point-to-point et 14 features Haralick, ce qui simplifie la sélection de la meilleur feature. Par la suite, l'extracteur de features Haralick est donc utilisé avec ces paramètres (`distance=2`, `return_mean_ptp=True` et `compute_14th_feature=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c73a88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((422, 28), (207, 28))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haralick = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean_ptp=True,\n",
    "                                         compute_14th_feature=True, distance=2) for f in files_train])\n",
    "haralick_test = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean_ptp=True,\n",
    "                                         compute_14th_feature=True, distance=2) for f in files_test])\n",
    "haralick.shape, haralick_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e951fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature                 </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS                   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\n",
       "<tr><td>Color channel statistics</td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\">    0.714     </td><td style=\"text-align: center;\">      0.669       </td><td style=\"text-align: center;\">0.762</td><td style=\"text-align: center;\">0.515</td><td style=\"text-align: center;\">       0.557        </td></tr>\n",
       "<tr><td>Hu moments              </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\">    0.146     </td><td style=\"text-align: center;\">      0.145       </td><td style=\"text-align: center;\">0.262</td><td style=\"text-align: center;\">0.226</td><td style=\"text-align: center;\">       0.247        </td></tr>\n",
       "<tr><td>Haralick                </td><td style=\"text-align: center;\">0.833</td><td style=\"text-align: center;\">    0.715     </td><td style=\"text-align: center;\">      0.682       </td><td style=\"text-align: center;\">0.754</td><td style=\"text-align: center;\">0.612</td><td style=\"text-align: center;\">       0.624        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature                 </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS                   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\\n<tr><td>Color channel statistics</td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\">    0.714     </td><td style=\"text-align: center;\">      0.669       </td><td style=\"text-align: center;\">0.762</td><td style=\"text-align: center;\">0.515</td><td style=\"text-align: center;\">       0.557        </td></tr>\\n<tr><td>Hu moments              </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\">    0.146     </td><td style=\"text-align: center;\">      0.145       </td><td style=\"text-align: center;\">0.262</td><td style=\"text-align: center;\">0.226</td><td style=\"text-align: center;\">       0.247        </td></tr>\\n<tr><td>Haralick                </td><td style=\"text-align: center;\">0.833</td><td style=\"text-align: center;\">    0.715     </td><td style=\"text-align: center;\">      0.682       </td><td style=\"text-align: center;\">0.754</td><td style=\"text-align: center;\">0.612</td><td style=\"text-align: center;\">       0.624        </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation\")\n",
    "f1_scores.append([\"Haralick\", score_svm8, score_rfc8, score_gboost8, score_knn8, score_lda8, score_lr8])\n",
    "tabulate(f1_scores, headers=[\"Feature\", \"SVM\", \"RandomForest\", \"GradientBoosting\", \"KNN\", \"LDA\", \"LogisticRegression\"],\n",
    "         tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1839f17",
   "metadata": {},
   "source": [
    "### Combinaisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b5ee8",
   "metadata": {},
   "source": [
    "Différentes combinaisons des features calculées sont testées dans cette section. Sont notamment testées PFTAS, Color channel statistics et Haralick avec et sans Hu Moments, pour vérifier si intégrer cette feature a réellement un impact. <br>\n",
    "<u>Sans Hu Moments </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2754ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([pftas, chan_stats, haralick], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d78925bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33755ed1e9874b229d91515d80adf5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for SVM is 0.8662926011350156 for C = 8\n"
     ]
    }
   ],
   "source": [
    "reg = range(1, 101)\n",
    "score = []\n",
    "for c in tqdm(reg):\n",
    "    svm = SVC(C=c)\n",
    "    score.append(np.mean(cross_val_score(svm, X_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score for SVM is {np.max(score)} for C = {np.argmax(score) + 1}\")\n",
    "score_svm = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "edad53e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Random Forest is 0.8140755345082268.\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "score_rfc = np.mean(cross_val_score(rfc, X, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Random Forest is {score_rfc}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1dca5d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Gradient Boosting is 0.7718510665893143.\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "score_gboost = np.mean(cross_val_score(gboost, X, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Gradient Boosting is {score_gboost}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a34300d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87cfddd1b16425dbb30eee28bffdf83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for KNN is 0.7902230371915202 for k = 1\n"
     ]
    }
   ],
   "source": [
    "neigh = range(1, 101)\n",
    "score = []\n",
    "for k in tqdm(neigh):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score.append(np.mean(cross_val_score(knn, X_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score for KNN is {np.max(score)} for k = {np.argmax(score) + 1}\")\n",
    "score_knn = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ea93505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LDA classifier is 0.798059570909464.\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "score_lda = np.mean(cross_val_score(lda, X, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for LDA classifier is {score_lda}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5fc2886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LDA classifier is 0.8149726885570903.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "score_lr = np.mean(cross_val_score(lr, X_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Logistic Regression classifier is {score_lr}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7bde3b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature                       </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS                         </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\n",
       "<tr><td>Color channel statistics      </td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\">    0.714     </td><td style=\"text-align: center;\">      0.669       </td><td style=\"text-align: center;\">0.762</td><td style=\"text-align: center;\">0.515</td><td style=\"text-align: center;\">       0.557        </td></tr>\n",
       "<tr><td>Hu moments                    </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\">    0.146     </td><td style=\"text-align: center;\">      0.145       </td><td style=\"text-align: center;\">0.262</td><td style=\"text-align: center;\">0.226</td><td style=\"text-align: center;\">       0.247        </td></tr>\n",
       "<tr><td>Haralick                      </td><td style=\"text-align: center;\">0.833</td><td style=\"text-align: center;\">    0.715     </td><td style=\"text-align: center;\">      0.682       </td><td style=\"text-align: center;\">0.754</td><td style=\"text-align: center;\">0.612</td><td style=\"text-align: center;\">       0.624        </td></tr>\n",
       "<tr><td>PFTAS + Color stats + Haralick</td><td style=\"text-align: center;\">0.866</td><td style=\"text-align: center;\">    0.814     </td><td style=\"text-align: center;\">      0.772       </td><td style=\"text-align: center;\">0.790</td><td style=\"text-align: center;\">0.798</td><td style=\"text-align: center;\">       0.815        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature                       </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS                         </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\\n<tr><td>Color channel statistics      </td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\">    0.714     </td><td style=\"text-align: center;\">      0.669       </td><td style=\"text-align: center;\">0.762</td><td style=\"text-align: center;\">0.515</td><td style=\"text-align: center;\">       0.557        </td></tr>\\n<tr><td>Hu moments                    </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\">    0.146     </td><td style=\"text-align: center;\">      0.145       </td><td style=\"text-align: center;\">0.262</td><td style=\"text-align: center;\">0.226</td><td style=\"text-align: center;\">       0.247        </td></tr>\\n<tr><td>Haralick                      </td><td style=\"text-align: center;\">0.833</td><td style=\"text-align: center;\">    0.715     </td><td style=\"text-align: center;\">      0.682       </td><td style=\"text-align: center;\">0.754</td><td style=\"text-align: center;\">0.612</td><td style=\"text-align: center;\">       0.624        </td></tr>\\n<tr><td>PFTAS + Color stats + Haralick</td><td style=\"text-align: center;\">0.866</td><td style=\"text-align: center;\">    0.814     </td><td style=\"text-align: center;\">      0.772       </td><td style=\"text-align: center;\">0.790</td><td style=\"text-align: center;\">0.798</td><td style=\"text-align: center;\">       0.815        </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation\")\n",
    "f1_scores.append([\"PFTAS + Color stats + Haralick\", score_svm, score_rfc, score_gboost, score_knn, score_lda, score_lr])\n",
    "tabulate(f1_scores, headers=[\"Feature\", \"SVM\", \"RandomForest\", \"GradientBoosting\", \"KNN\", \"LDA\", \"LogisticRegression\"],\n",
    "         tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c67e14",
   "metadata": {},
   "source": [
    "<u>Avec Hu Moments</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9f6eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([pftas, chan_stats, hu, haralick], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31eefc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c743c5089744d22934570a6cf1b271a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for SVM is 0.8676391203367699 for C = 6\n"
     ]
    }
   ],
   "source": [
    "reg = range(1, 101)\n",
    "score = []\n",
    "for c in tqdm(reg):\n",
    "    svm = SVC(C=c)\n",
    "    score.append(np.mean(cross_val_score(svm, X_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score for SVM is {np.max(score)} for C = {np.argmax(score) + 1}\")\n",
    "score_svm = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc3b0f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Random Forest is 0.8190478512860992.\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "score_rfc = np.mean(cross_val_score(rfc, X, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Random Forest is {score_rfc}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77add1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Gradient Boosting is 0.7727443625146616.\n"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "score_gboost = np.mean(cross_val_score(gboost, X, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Gradient Boosting is {score_gboost}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b1c185f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232e42fcbb314e7a98bd610a1f43d8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for KNN is 0.7928882405778773 for k = 1\n"
     ]
    }
   ],
   "source": [
    "neigh = range(1, 101)\n",
    "score = []\n",
    "for k in tqdm(neigh):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score.append(np.mean(cross_val_score(knn, X_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "print(f\"Best score for KNN is {np.max(score)} for k = {np.argmax(score) + 1}\")\n",
    "score_knn = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b801bdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LDA classifier is 0.7852804988221656.\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "score_lda = np.mean(cross_val_score(lda, X, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for LDA classifier is {score_lda}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dca162d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LDA classifier is 0.8138325923048146.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "score_lr = np.mean(cross_val_score(lr, X_scaled, y_train, cv=16, scoring=\"f1_weighted\"))\n",
    "print(f\"Score for Logistic Regression classifier is {score_lr}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49a1a6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature                            </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS                              </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\n",
       "<tr><td>Color channel statistics           </td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\">    0.714     </td><td style=\"text-align: center;\">      0.669       </td><td style=\"text-align: center;\">0.762</td><td style=\"text-align: center;\">0.515</td><td style=\"text-align: center;\">       0.557        </td></tr>\n",
       "<tr><td>Hu moments                         </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\">    0.146     </td><td style=\"text-align: center;\">      0.145       </td><td style=\"text-align: center;\">0.262</td><td style=\"text-align: center;\">0.226</td><td style=\"text-align: center;\">       0.247        </td></tr>\n",
       "<tr><td>Haralick                           </td><td style=\"text-align: center;\">0.833</td><td style=\"text-align: center;\">    0.715     </td><td style=\"text-align: center;\">      0.682       </td><td style=\"text-align: center;\">0.754</td><td style=\"text-align: center;\">0.612</td><td style=\"text-align: center;\">       0.624        </td></tr>\n",
       "<tr><td>PFTAS + Color stats + Haralick     </td><td style=\"text-align: center;\">0.866</td><td style=\"text-align: center;\">    0.814     </td><td style=\"text-align: center;\">      0.772       </td><td style=\"text-align: center;\">0.790</td><td style=\"text-align: center;\">0.798</td><td style=\"text-align: center;\">       0.815        </td></tr>\n",
       "<tr><td>PFTAS + Color stats + Hu + Haralick</td><td style=\"text-align: center;\">0.868</td><td style=\"text-align: center;\">    0.819     </td><td style=\"text-align: center;\">      0.773       </td><td style=\"text-align: center;\">0.793</td><td style=\"text-align: center;\">0.785</td><td style=\"text-align: center;\">       0.814        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature                            </th><th style=\"text-align: center;\"> SVM </th><th style=\"text-align: center;\"> RandomForest </th><th style=\"text-align: center;\"> GradientBoosting </th><th style=\"text-align: center;\"> KNN </th><th style=\"text-align: center;\"> LDA </th><th style=\"text-align: center;\"> LogisticRegression </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS                              </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\">    0.773     </td><td style=\"text-align: center;\">      0.751       </td><td style=\"text-align: center;\">0.763</td><td style=\"text-align: center;\">0.723</td><td style=\"text-align: center;\">       0.766        </td></tr>\\n<tr><td>Color channel statistics           </td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\">    0.714     </td><td style=\"text-align: center;\">      0.669       </td><td style=\"text-align: center;\">0.762</td><td style=\"text-align: center;\">0.515</td><td style=\"text-align: center;\">       0.557        </td></tr>\\n<tr><td>Hu moments                         </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\">    0.146     </td><td style=\"text-align: center;\">      0.145       </td><td style=\"text-align: center;\">0.262</td><td style=\"text-align: center;\">0.226</td><td style=\"text-align: center;\">       0.247        </td></tr>\\n<tr><td>Haralick                           </td><td style=\"text-align: center;\">0.833</td><td style=\"text-align: center;\">    0.715     </td><td style=\"text-align: center;\">      0.682       </td><td style=\"text-align: center;\">0.754</td><td style=\"text-align: center;\">0.612</td><td style=\"text-align: center;\">       0.624        </td></tr>\\n<tr><td>PFTAS + Color stats + Haralick     </td><td style=\"text-align: center;\">0.866</td><td style=\"text-align: center;\">    0.814     </td><td style=\"text-align: center;\">      0.772       </td><td style=\"text-align: center;\">0.790</td><td style=\"text-align: center;\">0.798</td><td style=\"text-align: center;\">       0.815        </td></tr>\\n<tr><td>PFTAS + Color stats + Hu + Haralick</td><td style=\"text-align: center;\">0.868</td><td style=\"text-align: center;\">    0.819     </td><td style=\"text-align: center;\">      0.773       </td><td style=\"text-align: center;\">0.793</td><td style=\"text-align: center;\">0.785</td><td style=\"text-align: center;\">       0.814        </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation\")\n",
    "f1_scores.append([\"PFTAS + Color stats + Hu + Haralick\", score_svm, score_rfc, score_gboost, score_knn, score_lda, score_lr])\n",
    "tabulate(f1_scores, headers=[\"Feature\", \"SVM\", \"RandomForest\", \"GradientBoosting\", \"KNN\", \"LDA\", \"LogisticRegression\"],\n",
    "         tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c215d3",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;On remarque donc que combiner les features augmente drastiquement le F1-score global obtenu, ceci avec tous les classifieurs. La feature des Hu moment, qui ne permet pas d'avoir un bon score par elle-même, semble participer à l'amélioration du score obtenu avec la plupart des classifieurs testés. <br><br>\n",
    "&nbsp;&nbsp;**Le classifieur SVM permet d'obtenir un meilleur score de manière systématique**, et ce seulement en optimisant la valeur de l'hyperparamètre C. Les hyperparamètres optimaux des classifieurs RandomForest et GradientBoosting n'ont pas été recherchés, mais ceux-ci sont nombreux et n'ont pas un impact unitaire aussi important que le coefficient de régularisation du SVM. Au vu des résultats obtenus, j'ai donc décidé d'optimiser un classifieur SVM par la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59d8858",
   "metadata": {},
   "source": [
    "### Comparaison de kernels SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fd548",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;Plusieurs articles parlent de kernels à intersection d'histogramme (http://perso.lcpc.fr/tarel.jean-philippe/publis/jpt-icip05.pdf, https://www.scirp.org/pdf/JCC_2015112015262272.pdf, ...), qui ne sont pas implémentés dans scikit-learn. J'ai trouvé le **GitHub suivant qui implémente un nombre important de kernels compatibles avec Scikit-learn : https://github.com/gmum/pykernels** <br>\n",
    "Test d'une série de kernels sur les features précédentes pour trouver le plus intéressant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82122dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = {\"Exponential\":pykernels.Exponential(), \"Laplacian\":pykernels.Laplacian(), \"Cauchy\":pykernels.Cauchy(),\n",
    "           \"TStudent\":pykernels.TStudent(), \"Min\":pykernels.Min(), \"Log\":pykernels.Log(),\n",
    "           \"Power\":pykernels.Power(), \"HistoIntersection\":pykernels.GeneralizedHistogramIntersection(),\n",
    "           \"Tanimoto\":pykernels.Tanimoto(), \"Sorensen\":pykernels.Sorensen(), \"RBF\":\"rbf\", \"Linear\":\"linear\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e60349d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be976296e1704250b8b3a83c8dfd4e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for kernel Exponential is 0.8279747174912773 for C = 38\n",
      "Best score for kernel Laplacian is 0.8279747174912773 for C = 38\n",
      "Best score for kernel Cauchy is 0.8326985529309247 for C = 13\n",
      "Best score for kernel TStudent is 0.42961550152635447 for C = 2\n",
      "Best score for kernel Min is 0.8120315483029159 for C = 1\n",
      "Best score for kernel Log is 0.8036666167008046 for C = 1\n",
      "Best score for kernel Power is 0.1825612766138867 for C = 32\n",
      "Best score for kernel GeneralizedHistogramIntersection is 0.7537703951833225 for C = 1\n",
      "Best score for kernel Tanimoto is 0.833345194296049 for C = 11\n",
      "Best score for kernel Sorensen is 0.8102855186322067 for C = 88\n",
      "Best score for kernel rbf is 0.8209024919762099 for C = 17\n",
      "Best score for kernel linear is 0.772078391990251 for C = 3\n"
     ]
    }
   ],
   "source": [
    "# PFTAS\n",
    "score_svm = {}\n",
    "for name, kern in tqdm(kernels.items()) :\n",
    "    reg = range(1, 101)\n",
    "    score = []\n",
    "    for c in reg:\n",
    "        svm = SVC(C=c, kernel=kern)\n",
    "        score.append(np.mean(cross_val_score(svm, pftas_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    print(f\"Best score for kernel {kern} is {np.max(score)} for C = {np.argmax(score) + 1}\")\n",
    "    score_svm[name] = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "187f02a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation par kernel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature  </th><th style=\"text-align: center;\"> Exponential </th><th style=\"text-align: center;\"> Laplacian </th><th style=\"text-align: center;\"> Cauchy </th><th style=\"text-align: center;\"> TStudent </th><th style=\"text-align: center;\"> Min </th><th style=\"text-align: center;\"> Log </th><th style=\"text-align: center;\"> Power </th><th style=\"text-align: center;\"> HistoIntersection </th><th style=\"text-align: center;\"> Tanimoto </th><th style=\"text-align: center;\"> Sorensen </th><th style=\"text-align: center;\"> RBF </th><th style=\"text-align: center;\"> Linear </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS    </td><td style=\"text-align: center;\">    0.828    </td><td style=\"text-align: center;\">   0.828   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.430   </td><td style=\"text-align: center;\">0.812</td><td style=\"text-align: center;\">0.804</td><td style=\"text-align: center;\"> 0.183 </td><td style=\"text-align: center;\">       0.754       </td><td style=\"text-align: center;\">  0.833   </td><td style=\"text-align: center;\">  0.810   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\"> 0.772  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature  </th><th style=\"text-align: center;\"> Exponential </th><th style=\"text-align: center;\"> Laplacian </th><th style=\"text-align: center;\"> Cauchy </th><th style=\"text-align: center;\"> TStudent </th><th style=\"text-align: center;\"> Min </th><th style=\"text-align: center;\"> Log </th><th style=\"text-align: center;\"> Power </th><th style=\"text-align: center;\"> HistoIntersection </th><th style=\"text-align: center;\"> Tanimoto </th><th style=\"text-align: center;\"> Sorensen </th><th style=\"text-align: center;\"> RBF </th><th style=\"text-align: center;\"> Linear </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS    </td><td style=\"text-align: center;\">    0.828    </td><td style=\"text-align: center;\">   0.828   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.430   </td><td style=\"text-align: center;\">0.812</td><td style=\"text-align: center;\">0.804</td><td style=\"text-align: center;\"> 0.183 </td><td style=\"text-align: center;\">       0.754       </td><td style=\"text-align: center;\">  0.833   </td><td style=\"text-align: center;\">  0.810   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\"> 0.772  </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation par kernel\")\n",
    "f1_kernels = []\n",
    "headers = [\"Feature\"]\n",
    "headers.extend([k for k in kernels.keys()])\n",
    "row = [\"PFTAS\"]\n",
    "row.extend([s for s in score_svm.values()])\n",
    "f1_kernels.append(row)\n",
    "tabulate(f1_kernels, headers=headers, tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c19fe055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53402050051a40f89af85835c2ba195e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for kernel Exponential is 0.8119612324206341 for C = 17\n",
      "Best score for kernel Laplacian is 0.8119612324206341 for C = 17\n",
      "Best score for kernel Cauchy is 0.8329321161586118 for C = 21\n",
      "Best score for kernel TStudent is 0.7839089724773485 for C = 3\n",
      "Best score for kernel Min is 0.7490773580250076 for C = 2\n",
      "Best score for kernel Log is 0.771498063111311 for C = 2\n",
      "Best score for kernel Power is 0.1784455540707236 for C = 1\n",
      "Best score for kernel GeneralizedHistogramIntersection is 0.5900364350260654 for C = 2\n",
      "Best score for kernel Tanimoto is 0.8305222990052049 for C = 26\n",
      "Best score for kernel Sorensen is 0.7691421682741126 for C = 37\n",
      "Best score for kernel rbf is 0.822807826867656 for C = 29\n",
      "Best score for kernel linear is 0.6915440506786661 for C = 6\n"
     ]
    }
   ],
   "source": [
    "# Color statistics\n",
    "score_svm = {}\n",
    "for name, kern in tqdm(kernels.items()) :\n",
    "    reg = range(1, 101)\n",
    "    score = []\n",
    "    for c in reg:\n",
    "        svm = SVC(C=c, kernel=kern)\n",
    "        score.append(np.mean(cross_val_score(svm, chan_stats_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    print(f\"Best score for kernel {kern} is {np.max(score)} for C = {np.argmax(score) + 1}\")\n",
    "    score_svm[name] = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea415a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation par kernel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature                 </th><th style=\"text-align: center;\"> Exponential </th><th style=\"text-align: center;\"> Laplacian </th><th style=\"text-align: center;\"> Cauchy </th><th style=\"text-align: center;\"> TStudent </th><th style=\"text-align: center;\"> Min </th><th style=\"text-align: center;\"> Log </th><th style=\"text-align: center;\"> Power </th><th style=\"text-align: center;\"> HistoIntersection </th><th style=\"text-align: center;\"> Tanimoto </th><th style=\"text-align: center;\"> Sorensen </th><th style=\"text-align: center;\"> RBF </th><th style=\"text-align: center;\"> Linear </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS                   </td><td style=\"text-align: center;\">    0.828    </td><td style=\"text-align: center;\">   0.828   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.430   </td><td style=\"text-align: center;\">0.812</td><td style=\"text-align: center;\">0.804</td><td style=\"text-align: center;\"> 0.183 </td><td style=\"text-align: center;\">       0.754       </td><td style=\"text-align: center;\">  0.833   </td><td style=\"text-align: center;\">  0.810   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\"> 0.772  </td></tr>\n",
       "<tr><td>Color channel statistics</td><td style=\"text-align: center;\">    0.812    </td><td style=\"text-align: center;\">   0.812   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.784   </td><td style=\"text-align: center;\">0.749</td><td style=\"text-align: center;\">0.771</td><td style=\"text-align: center;\"> 0.178 </td><td style=\"text-align: center;\">       0.590       </td><td style=\"text-align: center;\">  0.831   </td><td style=\"text-align: center;\">  0.769   </td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\"> 0.692  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature                 </th><th style=\"text-align: center;\"> Exponential </th><th style=\"text-align: center;\"> Laplacian </th><th style=\"text-align: center;\"> Cauchy </th><th style=\"text-align: center;\"> TStudent </th><th style=\"text-align: center;\"> Min </th><th style=\"text-align: center;\"> Log </th><th style=\"text-align: center;\"> Power </th><th style=\"text-align: center;\"> HistoIntersection </th><th style=\"text-align: center;\"> Tanimoto </th><th style=\"text-align: center;\"> Sorensen </th><th style=\"text-align: center;\"> RBF </th><th style=\"text-align: center;\"> Linear </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS                   </td><td style=\"text-align: center;\">    0.828    </td><td style=\"text-align: center;\">   0.828   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.430   </td><td style=\"text-align: center;\">0.812</td><td style=\"text-align: center;\">0.804</td><td style=\"text-align: center;\"> 0.183 </td><td style=\"text-align: center;\">       0.754       </td><td style=\"text-align: center;\">  0.833   </td><td style=\"text-align: center;\">  0.810   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\"> 0.772  </td></tr>\\n<tr><td>Color channel statistics</td><td style=\"text-align: center;\">    0.812    </td><td style=\"text-align: center;\">   0.812   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.784   </td><td style=\"text-align: center;\">0.749</td><td style=\"text-align: center;\">0.771</td><td style=\"text-align: center;\"> 0.178 </td><td style=\"text-align: center;\">       0.590       </td><td style=\"text-align: center;\">  0.831   </td><td style=\"text-align: center;\">  0.769   </td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\"> 0.692  </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation par kernel\")\n",
    "headers = [\"Feature\"]\n",
    "headers.extend([k for k in kernels.keys()])\n",
    "row = [\"Color channel statistics\"]\n",
    "row.extend([s for s in score_svm.values()])\n",
    "f1_kernels.append(row)\n",
    "tabulate(f1_kernels, headers=headers, tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22de10eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5c63e2fdfd4567b698d5c1d0d0ec9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for kernel Exponential is 0.2638902941787557 for C = 100\n",
      "Best score for kernel Laplacian is 0.2638902941787557 for C = 100\n",
      "Best score for kernel Cauchy is 0.25874356430288237 for C = 8\n",
      "Best score for kernel TStudent is 0.27314518364865586 for C = 41\n",
      "Best score for kernel Min is 0.27693513973562056 for C = 5\n",
      "Best score for kernel Log is 0.2269498876202936 for C = 49\n",
      "Best score for kernel Power is 0.184927886036719 for C = 1\n",
      "Best score for kernel GeneralizedHistogramIntersection is 0.22811472189221688 for C = 3\n",
      "Best score for kernel Tanimoto is 0.28106957343068456 for C = 18\n",
      "Best score for kernel Sorensen is 0.25511755279383486 for C = 23\n",
      "Best score for kernel rbf is 0.27556334606948923 for C = 45\n",
      "Best score for kernel linear is 0.21477082019129176 for C = 69\n"
     ]
    }
   ],
   "source": [
    "# Hu Moments\n",
    "score_svm = {}\n",
    "for name, kern in tqdm(kernels.items()) :\n",
    "    reg = range(1, 101)\n",
    "    score = []\n",
    "    for c in reg:\n",
    "        svm = SVC(C=c, kernel=kern)\n",
    "        score.append(np.mean(cross_val_score(svm, hu_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    print(f\"Best score for kernel {kern} is {np.max(score)} for C = {np.argmax(score) + 1}\")\n",
    "    score_svm[name] = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cdbe07a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation par kernel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature                 </th><th style=\"text-align: center;\"> Exponential </th><th style=\"text-align: center;\"> Laplacian </th><th style=\"text-align: center;\"> Cauchy </th><th style=\"text-align: center;\"> TStudent </th><th style=\"text-align: center;\"> Min </th><th style=\"text-align: center;\"> Log </th><th style=\"text-align: center;\"> Power </th><th style=\"text-align: center;\"> HistoIntersection </th><th style=\"text-align: center;\"> Tanimoto </th><th style=\"text-align: center;\"> Sorensen </th><th style=\"text-align: center;\"> RBF </th><th style=\"text-align: center;\"> Linear </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS                   </td><td style=\"text-align: center;\">    0.828    </td><td style=\"text-align: center;\">   0.828   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.430   </td><td style=\"text-align: center;\">0.812</td><td style=\"text-align: center;\">0.804</td><td style=\"text-align: center;\"> 0.183 </td><td style=\"text-align: center;\">       0.754       </td><td style=\"text-align: center;\">  0.833   </td><td style=\"text-align: center;\">  0.810   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\"> 0.772  </td></tr>\n",
       "<tr><td>Color channel statistics</td><td style=\"text-align: center;\">    0.812    </td><td style=\"text-align: center;\">   0.812   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.784   </td><td style=\"text-align: center;\">0.749</td><td style=\"text-align: center;\">0.771</td><td style=\"text-align: center;\"> 0.178 </td><td style=\"text-align: center;\">       0.590       </td><td style=\"text-align: center;\">  0.831   </td><td style=\"text-align: center;\">  0.769   </td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\"> 0.692  </td></tr>\n",
       "<tr><td>Hu                      </td><td style=\"text-align: center;\">    0.264    </td><td style=\"text-align: center;\">   0.264   </td><td style=\"text-align: center;\"> 0.259  </td><td style=\"text-align: center;\">  0.273   </td><td style=\"text-align: center;\">0.277</td><td style=\"text-align: center;\">0.227</td><td style=\"text-align: center;\"> 0.185 </td><td style=\"text-align: center;\">       0.228       </td><td style=\"text-align: center;\">  0.281   </td><td style=\"text-align: center;\">  0.255   </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\"> 0.215  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature                 </th><th style=\"text-align: center;\"> Exponential </th><th style=\"text-align: center;\"> Laplacian </th><th style=\"text-align: center;\"> Cauchy </th><th style=\"text-align: center;\"> TStudent </th><th style=\"text-align: center;\"> Min </th><th style=\"text-align: center;\"> Log </th><th style=\"text-align: center;\"> Power </th><th style=\"text-align: center;\"> HistoIntersection </th><th style=\"text-align: center;\"> Tanimoto </th><th style=\"text-align: center;\"> Sorensen </th><th style=\"text-align: center;\"> RBF </th><th style=\"text-align: center;\"> Linear </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS                   </td><td style=\"text-align: center;\">    0.828    </td><td style=\"text-align: center;\">   0.828   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.430   </td><td style=\"text-align: center;\">0.812</td><td style=\"text-align: center;\">0.804</td><td style=\"text-align: center;\"> 0.183 </td><td style=\"text-align: center;\">       0.754       </td><td style=\"text-align: center;\">  0.833   </td><td style=\"text-align: center;\">  0.810   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\"> 0.772  </td></tr>\\n<tr><td>Color channel statistics</td><td style=\"text-align: center;\">    0.812    </td><td style=\"text-align: center;\">   0.812   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.784   </td><td style=\"text-align: center;\">0.749</td><td style=\"text-align: center;\">0.771</td><td style=\"text-align: center;\"> 0.178 </td><td style=\"text-align: center;\">       0.590       </td><td style=\"text-align: center;\">  0.831   </td><td style=\"text-align: center;\">  0.769   </td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\"> 0.692  </td></tr>\\n<tr><td>Hu                      </td><td style=\"text-align: center;\">    0.264    </td><td style=\"text-align: center;\">   0.264   </td><td style=\"text-align: center;\"> 0.259  </td><td style=\"text-align: center;\">  0.273   </td><td style=\"text-align: center;\">0.277</td><td style=\"text-align: center;\">0.227</td><td style=\"text-align: center;\"> 0.185 </td><td style=\"text-align: center;\">       0.228       </td><td style=\"text-align: center;\">  0.281   </td><td style=\"text-align: center;\">  0.255   </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\"> 0.215  </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation par kernel\")\n",
    "headers = [\"Feature\"]\n",
    "headers.extend([k for k in kernels.keys()])\n",
    "row = [\"Hu\"]\n",
    "row.extend([s for s in score_svm.values()])\n",
    "f1_kernels.append(row)\n",
    "tabulate(f1_kernels, headers=headers, tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e00ae6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd94f24bd6a84959abf0078f974639cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for kernel Exponential is 0.8274550058203904 for C = 27\n",
      "Best score for kernel Laplacian is 0.8274550058203904 for C = 27\n",
      "Best score for kernel Cauchy is 0.8498781835053202 for C = 23\n",
      "Best score for kernel TStudent is 0.7130913759605942 for C = 3\n",
      "Best score for kernel Min is 0.767439025638812 for C = 1\n",
      "Best score for kernel Log is 0.8286248113037642 for C = 2\n",
      "Best score for kernel Power is 0.1752531863910069 for C = 1\n",
      "Best score for kernel GeneralizedHistogramIntersection is 0.6053658572355153 for C = 2\n",
      "Best score for kernel Tanimoto is 0.8329801776650068 for C = 7\n",
      "Best score for kernel Sorensen is 0.7682852680715929 for C = 34\n",
      "Best score for kernel rbf is 0.8333612385161531 for C = 38\n",
      "Best score for kernel linear is 0.7305527093988633 for C = 100\n"
     ]
    }
   ],
   "source": [
    "# Haralick\n",
    "haralick_scaled = scaler.fit_transform(haralick)\n",
    "score_svm = {}\n",
    "for name, kern in tqdm(kernels.items()) :\n",
    "    reg = range(1, 101)\n",
    "    score = []\n",
    "    for c in reg:\n",
    "        svm = SVC(C=c, kernel=kern)\n",
    "        score.append(np.mean(cross_val_score(svm, haralick_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    print(f\"Best score for kernel {kern} is {np.max(score)} for C = {np.argmax(score) + 1}\")\n",
    "    score_svm[name] = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cfcd60c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation par kernel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature                 </th><th style=\"text-align: center;\"> Exponential </th><th style=\"text-align: center;\"> Laplacian </th><th style=\"text-align: center;\"> Cauchy </th><th style=\"text-align: center;\"> TStudent </th><th style=\"text-align: center;\"> Min </th><th style=\"text-align: center;\"> Log </th><th style=\"text-align: center;\"> Power </th><th style=\"text-align: center;\"> HistoIntersection </th><th style=\"text-align: center;\"> Tanimoto </th><th style=\"text-align: center;\"> Sorensen </th><th style=\"text-align: center;\"> RBF </th><th style=\"text-align: center;\"> Linear </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS                   </td><td style=\"text-align: center;\">    0.828    </td><td style=\"text-align: center;\">   0.828   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.430   </td><td style=\"text-align: center;\">0.812</td><td style=\"text-align: center;\">0.804</td><td style=\"text-align: center;\"> 0.183 </td><td style=\"text-align: center;\">       0.754       </td><td style=\"text-align: center;\">  0.833   </td><td style=\"text-align: center;\">  0.810   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\"> 0.772  </td></tr>\n",
       "<tr><td>Color channel statistics</td><td style=\"text-align: center;\">    0.812    </td><td style=\"text-align: center;\">   0.812   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.784   </td><td style=\"text-align: center;\">0.749</td><td style=\"text-align: center;\">0.771</td><td style=\"text-align: center;\"> 0.178 </td><td style=\"text-align: center;\">       0.590       </td><td style=\"text-align: center;\">  0.831   </td><td style=\"text-align: center;\">  0.769   </td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\"> 0.692  </td></tr>\n",
       "<tr><td>Hu                      </td><td style=\"text-align: center;\">    0.264    </td><td style=\"text-align: center;\">   0.264   </td><td style=\"text-align: center;\"> 0.259  </td><td style=\"text-align: center;\">  0.273   </td><td style=\"text-align: center;\">0.277</td><td style=\"text-align: center;\">0.227</td><td style=\"text-align: center;\"> 0.185 </td><td style=\"text-align: center;\">       0.228       </td><td style=\"text-align: center;\">  0.281   </td><td style=\"text-align: center;\">  0.255   </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\"> 0.215  </td></tr>\n",
       "<tr><td>Haralick                </td><td style=\"text-align: center;\">    0.827    </td><td style=\"text-align: center;\">   0.827   </td><td style=\"text-align: center;\"> 0.850  </td><td style=\"text-align: center;\">  0.713   </td><td style=\"text-align: center;\">0.767</td><td style=\"text-align: center;\">0.829</td><td style=\"text-align: center;\"> 0.175 </td><td style=\"text-align: center;\">       0.605       </td><td style=\"text-align: center;\">  0.833   </td><td style=\"text-align: center;\">  0.768   </td><td style=\"text-align: center;\">0.833</td><td style=\"text-align: center;\"> 0.731  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature                 </th><th style=\"text-align: center;\"> Exponential </th><th style=\"text-align: center;\"> Laplacian </th><th style=\"text-align: center;\"> Cauchy </th><th style=\"text-align: center;\"> TStudent </th><th style=\"text-align: center;\"> Min </th><th style=\"text-align: center;\"> Log </th><th style=\"text-align: center;\"> Power </th><th style=\"text-align: center;\"> HistoIntersection </th><th style=\"text-align: center;\"> Tanimoto </th><th style=\"text-align: center;\"> Sorensen </th><th style=\"text-align: center;\"> RBF </th><th style=\"text-align: center;\"> Linear </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS                   </td><td style=\"text-align: center;\">    0.828    </td><td style=\"text-align: center;\">   0.828   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.430   </td><td style=\"text-align: center;\">0.812</td><td style=\"text-align: center;\">0.804</td><td style=\"text-align: center;\"> 0.183 </td><td style=\"text-align: center;\">       0.754       </td><td style=\"text-align: center;\">  0.833   </td><td style=\"text-align: center;\">  0.810   </td><td style=\"text-align: center;\">0.821</td><td style=\"text-align: center;\"> 0.772  </td></tr>\\n<tr><td>Color channel statistics</td><td style=\"text-align: center;\">    0.812    </td><td style=\"text-align: center;\">   0.812   </td><td style=\"text-align: center;\"> 0.833  </td><td style=\"text-align: center;\">  0.784   </td><td style=\"text-align: center;\">0.749</td><td style=\"text-align: center;\">0.771</td><td style=\"text-align: center;\"> 0.178 </td><td style=\"text-align: center;\">       0.590       </td><td style=\"text-align: center;\">  0.831   </td><td style=\"text-align: center;\">  0.769   </td><td style=\"text-align: center;\">0.823</td><td style=\"text-align: center;\"> 0.692  </td></tr>\\n<tr><td>Hu                      </td><td style=\"text-align: center;\">    0.264    </td><td style=\"text-align: center;\">   0.264   </td><td style=\"text-align: center;\"> 0.259  </td><td style=\"text-align: center;\">  0.273   </td><td style=\"text-align: center;\">0.277</td><td style=\"text-align: center;\">0.227</td><td style=\"text-align: center;\"> 0.185 </td><td style=\"text-align: center;\">       0.228       </td><td style=\"text-align: center;\">  0.281   </td><td style=\"text-align: center;\">  0.255   </td><td style=\"text-align: center;\">0.276</td><td style=\"text-align: center;\"> 0.215  </td></tr>\\n<tr><td>Haralick                </td><td style=\"text-align: center;\">    0.827    </td><td style=\"text-align: center;\">   0.827   </td><td style=\"text-align: center;\"> 0.850  </td><td style=\"text-align: center;\">  0.713   </td><td style=\"text-align: center;\">0.767</td><td style=\"text-align: center;\">0.829</td><td style=\"text-align: center;\"> 0.175 </td><td style=\"text-align: center;\">       0.605       </td><td style=\"text-align: center;\">  0.833   </td><td style=\"text-align: center;\">  0.768   </td><td style=\"text-align: center;\">0.833</td><td style=\"text-align: center;\"> 0.731  </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation par kernel\")\n",
    "headers = [\"Feature\"]\n",
    "headers.extend([k for k in kernels.keys()])\n",
    "row = [\"Haralick\"]\n",
    "row.extend([s for s in score_svm.values()])\n",
    "f1_kernels.append(row)\n",
    "tabulate(f1_kernels, headers=headers, tablefmt=\"html\", floatfmt=\".3f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bd6f4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([pftas, chan_stats, hu, haralick], axis=1)\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1663458c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b652a16da3e340fcb22300bd9b0f1bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for kernel Exponential is 0.8596175078680421 for C = 49\n",
      "Best score for kernel Laplacian is 0.8596175078680421 for C = 49\n",
      "Best score for kernel Cauchy is 0.8545912623503436 for C = 9\n",
      "Best score for kernel TStudent is 0.334470339184917 for C = 2\n",
      "Best score for kernel Min is 0.8625727548804472 for C = 1\n",
      "Best score for kernel Log is 0.8160248800740253 for C = 1\n",
      "Best score for kernel Power is 0.18408003519604166 for C = 12\n",
      "Best score for kernel GeneralizedHistogramIntersection is 0.8015891076120778 for C = 1\n",
      "Best score for kernel Tanimoto is 0.867796910077893 for C = 7\n",
      "Best score for kernel Sorensen is 0.8414798861513605 for C = 16\n",
      "Best score for kernel rbf is 0.8676391203367699 for C = 6\n",
      "Best score for kernel linear is 0.8295373163161623 for C = 2\n"
     ]
    }
   ],
   "source": [
    "# Combinaison\n",
    "score_svm = {}\n",
    "for name, kern in tqdm(kernels.items()) :\n",
    "    reg = range(1, 101)\n",
    "    score = []\n",
    "    for c in reg:\n",
    "        svm = SVC(C=c, kernel=kern)\n",
    "        score.append(np.mean(cross_val_score(svm, X_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    print(f\"Best score for kernel {kern} is {np.max(score)} for C = {np.argmax(score) + 1}\")\n",
    "    score_svm[name] = np.max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "682b46c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récapitulatif des F1-scores obtenus par Cross Validation par kernel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Feature                            </th><th style=\"text-align: center;\"> Exponential </th><th style=\"text-align: center;\"> Laplacian </th><th style=\"text-align: center;\"> Cauchy </th><th style=\"text-align: center;\"> TStudent </th><th style=\"text-align: center;\"> Min  </th><th style=\"text-align: center;\"> Log  </th><th style=\"text-align: center;\"> Power </th><th style=\"text-align: center;\"> HistoIntersection </th><th style=\"text-align: center;\"> Tanimoto </th><th style=\"text-align: center;\"> Sorensen </th><th style=\"text-align: center;\"> RBF  </th><th style=\"text-align: center;\"> Linear </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PFTAS                              </td><td style=\"text-align: center;\">   0.8280    </td><td style=\"text-align: center;\">  0.8280   </td><td style=\"text-align: center;\"> 0.8327 </td><td style=\"text-align: center;\">  0.4296  </td><td style=\"text-align: center;\">0.8120</td><td style=\"text-align: center;\">0.8037</td><td style=\"text-align: center;\">0.1826 </td><td style=\"text-align: center;\">      0.7538       </td><td style=\"text-align: center;\">  0.8333  </td><td style=\"text-align: center;\">  0.8103  </td><td style=\"text-align: center;\">0.8209</td><td style=\"text-align: center;\"> 0.7721 </td></tr>\n",
       "<tr><td>Color channel statistics           </td><td style=\"text-align: center;\">   0.8120    </td><td style=\"text-align: center;\">  0.8120   </td><td style=\"text-align: center;\"> 0.8329 </td><td style=\"text-align: center;\">  0.7839  </td><td style=\"text-align: center;\">0.7491</td><td style=\"text-align: center;\">0.7715</td><td style=\"text-align: center;\">0.1784 </td><td style=\"text-align: center;\">      0.5900       </td><td style=\"text-align: center;\">  0.8305  </td><td style=\"text-align: center;\">  0.7691  </td><td style=\"text-align: center;\">0.8228</td><td style=\"text-align: center;\"> 0.6915 </td></tr>\n",
       "<tr><td>Hu                                 </td><td style=\"text-align: center;\">   0.2639    </td><td style=\"text-align: center;\">  0.2639   </td><td style=\"text-align: center;\"> 0.2587 </td><td style=\"text-align: center;\">  0.2731  </td><td style=\"text-align: center;\">0.2769</td><td style=\"text-align: center;\">0.2269</td><td style=\"text-align: center;\">0.1849 </td><td style=\"text-align: center;\">      0.2281       </td><td style=\"text-align: center;\">  0.2811  </td><td style=\"text-align: center;\">  0.2551  </td><td style=\"text-align: center;\">0.2756</td><td style=\"text-align: center;\"> 0.2148 </td></tr>\n",
       "<tr><td>Haralick                           </td><td style=\"text-align: center;\">   0.8275    </td><td style=\"text-align: center;\">  0.8275   </td><td style=\"text-align: center;\"> 0.8499 </td><td style=\"text-align: center;\">  0.7131  </td><td style=\"text-align: center;\">0.7674</td><td style=\"text-align: center;\">0.8286</td><td style=\"text-align: center;\">0.1753 </td><td style=\"text-align: center;\">      0.6054       </td><td style=\"text-align: center;\">  0.8330  </td><td style=\"text-align: center;\">  0.7683  </td><td style=\"text-align: center;\">0.8334</td><td style=\"text-align: center;\"> 0.7306 </td></tr>\n",
       "<tr><td>PFTAS + Color stats + Hu + Haralick</td><td style=\"text-align: center;\">   0.8596    </td><td style=\"text-align: center;\">  0.8596   </td><td style=\"text-align: center;\"> 0.8546 </td><td style=\"text-align: center;\">  0.3345  </td><td style=\"text-align: center;\">0.8626</td><td style=\"text-align: center;\">0.8160</td><td style=\"text-align: center;\">0.1841 </td><td style=\"text-align: center;\">      0.8016       </td><td style=\"text-align: center;\">  0.8678  </td><td style=\"text-align: center;\">  0.8415  </td><td style=\"text-align: center;\">0.8676</td><td style=\"text-align: center;\"> 0.8295 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Feature                            </th><th style=\"text-align: center;\"> Exponential </th><th style=\"text-align: center;\"> Laplacian </th><th style=\"text-align: center;\"> Cauchy </th><th style=\"text-align: center;\"> TStudent </th><th style=\"text-align: center;\"> Min  </th><th style=\"text-align: center;\"> Log  </th><th style=\"text-align: center;\"> Power </th><th style=\"text-align: center;\"> HistoIntersection </th><th style=\"text-align: center;\"> Tanimoto </th><th style=\"text-align: center;\"> Sorensen </th><th style=\"text-align: center;\"> RBF  </th><th style=\"text-align: center;\"> Linear </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>PFTAS                              </td><td style=\"text-align: center;\">   0.8280    </td><td style=\"text-align: center;\">  0.8280   </td><td style=\"text-align: center;\"> 0.8327 </td><td style=\"text-align: center;\">  0.4296  </td><td style=\"text-align: center;\">0.8120</td><td style=\"text-align: center;\">0.8037</td><td style=\"text-align: center;\">0.1826 </td><td style=\"text-align: center;\">      0.7538       </td><td style=\"text-align: center;\">  0.8333  </td><td style=\"text-align: center;\">  0.8103  </td><td style=\"text-align: center;\">0.8209</td><td style=\"text-align: center;\"> 0.7721 </td></tr>\\n<tr><td>Color channel statistics           </td><td style=\"text-align: center;\">   0.8120    </td><td style=\"text-align: center;\">  0.8120   </td><td style=\"text-align: center;\"> 0.8329 </td><td style=\"text-align: center;\">  0.7839  </td><td style=\"text-align: center;\">0.7491</td><td style=\"text-align: center;\">0.7715</td><td style=\"text-align: center;\">0.1784 </td><td style=\"text-align: center;\">      0.5900       </td><td style=\"text-align: center;\">  0.8305  </td><td style=\"text-align: center;\">  0.7691  </td><td style=\"text-align: center;\">0.8228</td><td style=\"text-align: center;\"> 0.6915 </td></tr>\\n<tr><td>Hu                                 </td><td style=\"text-align: center;\">   0.2639    </td><td style=\"text-align: center;\">  0.2639   </td><td style=\"text-align: center;\"> 0.2587 </td><td style=\"text-align: center;\">  0.2731  </td><td style=\"text-align: center;\">0.2769</td><td style=\"text-align: center;\">0.2269</td><td style=\"text-align: center;\">0.1849 </td><td style=\"text-align: center;\">      0.2281       </td><td style=\"text-align: center;\">  0.2811  </td><td style=\"text-align: center;\">  0.2551  </td><td style=\"text-align: center;\">0.2756</td><td style=\"text-align: center;\"> 0.2148 </td></tr>\\n<tr><td>Haralick                           </td><td style=\"text-align: center;\">   0.8275    </td><td style=\"text-align: center;\">  0.8275   </td><td style=\"text-align: center;\"> 0.8499 </td><td style=\"text-align: center;\">  0.7131  </td><td style=\"text-align: center;\">0.7674</td><td style=\"text-align: center;\">0.8286</td><td style=\"text-align: center;\">0.1753 </td><td style=\"text-align: center;\">      0.6054       </td><td style=\"text-align: center;\">  0.8330  </td><td style=\"text-align: center;\">  0.7683  </td><td style=\"text-align: center;\">0.8334</td><td style=\"text-align: center;\"> 0.7306 </td></tr>\\n<tr><td>PFTAS + Color stats + Hu + Haralick</td><td style=\"text-align: center;\">   0.8596    </td><td style=\"text-align: center;\">  0.8596   </td><td style=\"text-align: center;\"> 0.8546 </td><td style=\"text-align: center;\">  0.3345  </td><td style=\"text-align: center;\">0.8626</td><td style=\"text-align: center;\">0.8160</td><td style=\"text-align: center;\">0.1841 </td><td style=\"text-align: center;\">      0.8016       </td><td style=\"text-align: center;\">  0.8678  </td><td style=\"text-align: center;\">  0.8415  </td><td style=\"text-align: center;\">0.8676</td><td style=\"text-align: center;\"> 0.8295 </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Récapitulatif des F1-scores obtenus par Cross Validation par kernel\")\n",
    "headers = [\"Feature\"]\n",
    "headers.extend([k for k in kernels.keys()])\n",
    "row = [\"PFTAS + Color stats + Hu + Haralick\"]\n",
    "row.extend([s for s in score_svm.values()])\n",
    "f1_kernels.append(row)\n",
    "tabulate(f1_kernels, headers=headers, tablefmt=\"html\", floatfmt=\".4f\", numalign=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f762f9d4",
   "metadata": {},
   "source": [
    "Certains kernels semblent donc avoir des performances nettement supérieures aux autres. Le kernel \"Histogramme Intersection\" cité dans les articles précédents ne semble pas être le plus approprié pour cette tâche particulière !\n",
    "Le kernel avec les performances les plus importantes sur la combinaison des features est **Tanimoto**. Il a également des performances plus constantes sur les features testées unitairement. C'est donc celui que j'ai retenu. <br><br>\n",
    "<u>N.B. </u>: Certains kernels admettent des hyperparamètres supplémentaires (notamment Exponential, Laplacian ou Cauchy). J'ai joué avec le paramètre `s` du kernel Cauchy, qui après tuning permettait souvent de surpasser le score obtenu avec kernel de Tanimoto. Cependant, en pratique, j'ai observé que les soumissions effectuées avec ce kernel fournissaient un score plus bas que celles effectuées avec Tanimoto, même si le score de cross validation était plus élevé avec Cauchy. J'en ai donc déduit que l'hyperparamètre `s` du kernel de Cauchy causait de l'overfit, et ai préféré utiliser le kernel de Tanimoto. Les tests relatifs à ce kernel n'ont pas été inclus dans ce rapport pour ne pas l'alourdir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e884663",
   "metadata": {},
   "source": [
    "Le kernel de Tanimoto m'était inconnu jusqu'à présent, mais il apparaît que son implémentation en Python est relativement facile. Ci-dessous l'extrait du code de pykernels qui implémente le kernel de Tanimoto (avec un lien vers l'article scientifique dans lequel il est défini pour la 1ère fois). Il s'agit d'un kernel utilisé à l'origine en chimie informatique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d70644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanimoto(Kernel):\n",
    "    \"\"\"\n",
    "    Tanimoto kernel\n",
    "        K(x, y) = <x, y> / (||x||^2 + ||y||^2 - <x, y>)\n",
    "    as defined in:\n",
    "    \"Graph Kernels for Chemical Informatics\"\n",
    "    Liva Ralaivola, Sanjay J. Swamidass, Hiroto Saigo and Pierre Baldi\n",
    "    Neural Networks\n",
    "    http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.483&rep=rep1&type=pdf\n",
    "    \"\"\"\n",
    "    def _compute(self, data_1, data_2):\n",
    "\n",
    "        norm_1 = (data_1 ** 2).sum(axis=1).reshape(data_1.shape[0], 1)\n",
    "        norm_2 = (data_2 ** 2).sum(axis=1).reshape(data_2.shape[0], 1)\n",
    "        prod = data_1.dot(data_2.T)\n",
    "        return prod / (norm_1 + norm_2.T - prod)\n",
    "\n",
    "    def dim(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e69abf",
   "metadata": {},
   "source": [
    "## Optimisation de features avec le classifieur retenu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15238171",
   "metadata": {},
   "source": [
    "### Histogramme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8da83",
   "metadata": {},
   "source": [
    "Un histogramme de couleur est une feature basique de Computer Vision. Cependant, le nombre de feature généré par un histogramme peut être important en fonction du nombre de bins souhaité. Il était donc préférable d'adapter ce nombre de bins au classifieur retenu (ou de coupler cette méthode à une méthode de réduction de dimension). <br>\n",
    "Les classifieurs SVM avec kernels non linéaires peuvent traiter un grand nombre de features même avec un faible nombre d'observations, l'augmentation du nombre de bins avec le classifieur retenu n'est donc pas un problème. J'ai fait varier le nombre de bins entre 2 et 30 pour trouver une valeur permettant d'obtenir un bon score sans générer trop de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a91ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histo_features(bins, test_feature=False):\n",
    "    \"\"\" Créée des histogrammes de couleurs pour chaque canal HSV des images en input\n",
    "    Args:\n",
    "        bins (int) : nombre de bins (classes) à créer pour chaque canal de l'image HSV\n",
    "        test_feature (Bool): si True, crée des features sur les images de Test, si False créée \n",
    "                                des features sur les images de Train\n",
    "    Output:\n",
    "        X (numpy array) : features extraites (la dimension de sortie dépend du nombre de bins en argument)\n",
    "    \"\"\"\n",
    "    files = files_test if test_feature else files_train\n",
    "    X = []\n",
    "    for f in files:\n",
    "        hsv = cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2HSV)\n",
    "        hist  = cv2.calcHist([hsv], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "        cv2.normalize(hist, hist)\n",
    "        X.append(hist.flatten())\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7e774220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edeb067e73bd4e5b8abadbdf42c97a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins 2 : Best score 0.46747999151845304 - C 14 | Size of X (422, 8)\n",
      "Bins 3 : Best score 0.6545587642809865 - C 28 | Size of X (422, 27)\n",
      "Bins 4 : Best score 0.7265271572563239 - C 11 | Size of X (422, 64)\n",
      "Bins 5 : Best score 0.796167478552628 - C 13 | Size of X (422, 125)\n",
      "Bins 6 : Best score 0.8222336834382774 - C 9 | Size of X (422, 216)\n",
      "Bins 7 : Best score 0.8244958418836624 - C 21 | Size of X (422, 343)\n",
      "Bins 8 : Best score 0.8464483329467305 - C 5 | Size of X (422, 512)\n",
      "Bins 9 : Best score 0.8581969045911354 - C 10 | Size of X (422, 729)\n",
      "Bins 10 : Best score 0.8587316880452565 - C 4 | Size of X (422, 1000)\n",
      "Bins 11 : Best score 0.8469386471790318 - C 7 | Size of X (422, 1331)\n",
      "Bins 12 : Best score 0.8426695687780089 - C 10 | Size of X (422, 1728)\n",
      "Bins 13 : Best score 0.8701169794118512 - C 6 | Size of X (422, 2197)\n",
      "Bins 14 : Best score 0.8626062604695083 - C 4 | Size of X (422, 2744)\n",
      "Bins 15 : Best score 0.8761585389523424 - C 7 | Size of X (422, 3375)\n",
      "Bins 16 : Best score 0.8690210010589284 - C 3 | Size of X (422, 4096)\n",
      "Bins 17 : Best score 0.8616055898240726 - C 4 | Size of X (422, 4913)\n",
      "Bins 18 : Best score 0.8699481934257576 - C 9 | Size of X (422, 5832)\n",
      "Bins 19 : Best score 0.8666806909061182 - C 5 | Size of X (422, 6859)\n",
      "Bins 20 : Best score 0.8790544984455241 - C 10 | Size of X (422, 8000)\n",
      "Bins 21 : Best score 0.8670463484165407 - C 3 | Size of X (422, 9261)\n",
      "Bins 22 : Best score 0.8509829231784359 - C 5 | Size of X (422, 10648)\n",
      "Bins 23 : Best score 0.8775536972919451 - C 4 | Size of X (422, 12167)\n",
      "Bins 24 : Best score 0.8569679044839301 - C 6 | Size of X (422, 13824)\n",
      "Bins 25 : Best score 0.8627978769805693 - C 5 | Size of X (422, 15625)\n",
      "Bins 26 : Best score 0.8624025991814454 - C 4 | Size of X (422, 17576)\n",
      "Bins 27 : Best score 0.8693779155317617 - C 5 | Size of X (422, 19683)\n",
      "Bins 28 : Best score 0.8574583793066698 - C 4 | Size of X (422, 21952)\n",
      "Bins 29 : Best score 0.8749765162425419 - C 4 | Size of X (422, 24389)\n",
      "Bins 30 : Best score 0.8578967408027237 - C 5 | Size of X (422, 27000)\n"
     ]
    }
   ],
   "source": [
    "scores_histo = []\n",
    "for bins in tqdm(range(2, 31)):\n",
    "    X_tmp = create_histo_features(bins, test_feature=False)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_tmp)\n",
    "    reg = range(1, 51)\n",
    "    score = []\n",
    "    for c in reg:\n",
    "        svm = SVC(C=c, kernel=pykernels.Tanimoto())\n",
    "        score.append(np.mean(cross_val_score(svm, X_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    print(f\"Bins {bins} : Best score {np.max(score)} - C {np.argmax(score)+1} | Size of X {X_scaled.shape}\")\n",
    "    scores_histo.append(np.max(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c29b78c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(2, 31), scores_histo)\n",
    "plt.xlabel(\"Nombre de bins\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.title(\"Evolution du F1-score pour la feature histogramme en fonction du nombre de bins utilisés\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca1469",
   "metadata": {},
   "source": [
    "Meilleurs scores :\n",
    "* 20 bins : 0.879, avec 8000 features\n",
    "* 15 bins : 0.876, avec 3375 features\n",
    "* 13 bins : 0.870, avec 2197 features <br>\n",
    "Le meilleur compromis score / nombre de features semble être atteint pour 13 bins. <br>\n",
    "En utilisant uniquement les features générées avec  les histogrammes, le score obtenu en cross validation est meilleur qu'avec l'ensemble des features précédentes concaténées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3b4926ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((422, 2197), (207, 2197))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histo13 = create_histo_features(13, test_feature=False)\n",
    "histo13_test = create_histo_features(13, test_feature=True)\n",
    "histo13.shape, histo13_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d39b7d",
   "metadata": {},
   "source": [
    "### Local Binary Patterning (LBP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cad1d4",
   "metadata": {},
   "source": [
    "La librairie Mahotas permet de créer un histogramme de features LBP via la fonction `mahotas.features.lbp`. En revanche, le nombre de features retournées par cette méthode est très (trop) important. Comme conseillé sur le blog suivant (https://cvexplained.wordpress.com/2020/07/22/10-7-local-binary-patterns/), j'ai préféré utiliser l'implémentation de LBP proposée par skimage pour avoir plus de contrôle sur les features générées, et profiter d'une implémentation qui améliore l'invariance par rotation et niveaux de gris. <br>\n",
    "La génération de features nécessite de fournir un rayon et un nombre de points en entrée. Un nombre de points égal à 8 fois le rayon est recommandé pour rester cohérent avec l'implémentation de LBP, j'ai fait varier le rayon entre 1 et 10 pixels pour trouver une valeur optimale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "02211e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lbp_features(radius, points, test_feature=False):\n",
    "    \"\"\" Extrait les features LBP des images en input\n",
    "    Args:\n",
    "        radius (int) : rayon du cercle utilisé pour calculer les features LBP autour d'un pixel\n",
    "        points (int) : nombre de points à garder dans le cercle défini autour du pixel central\n",
    "                        Avec points = radius x 8, tous les points sont conservés\n",
    "        test_feature (Bool): si True, crée des features sur les images de Test, si False créée \n",
    "                                des features sur les images de Train\n",
    "    Output:\n",
    "        X (numpy array) : features extraites (la dimension de sortie dépend du nombre de bins en argument)\n",
    "    \"\"\"\n",
    "    files = files_test if test_feature else files_train\n",
    "    X = []\n",
    "    for f in files:\n",
    "        im = np.array(Image.open(f).convert('L'))\n",
    "        lbp = local_binary_pattern(im, points, radius, method=\"uniform\")\n",
    "        (hist, _) = np.histogram(lbp.ravel(), bins=range(0, points+3), range=(0, points+2))\n",
    "        X.append(hist)\n",
    "    return np.stack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f569b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ead99a98b0498db0f32d5200526b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rayon 1 : Best score 0.47838628509034486 - C 20 | Size of X (422, 10)\n",
      "Rayon 2 : Best score 0.6575136303234593 - C 9 | Size of X (422, 18)\n",
      "Rayon 3 : Best score 0.6476158097670164 - C 16 | Size of X (422, 26)\n",
      "Rayon 4 : Best score 0.6548318727805906 - C 31 | Size of X (422, 34)\n",
      "Rayon 5 : Best score 0.6758636212829588 - C 18 | Size of X (422, 42)\n",
      "Rayon 6 : Best score 0.7049250280820794 - C 13 | Size of X (422, 50)\n",
      "Rayon 7 : Best score 0.7074952810129093 - C 8 | Size of X (422, 58)\n",
      "Rayon 8 : Best score 0.702283852484173 - C 10 | Size of X (422, 66)\n",
      "Rayon 9 : Best score 0.6983171288192656 - C 5 | Size of X (422, 74)\n",
      "Rayon 10 : Best score 0.6696628434876298 - C 4 | Size of X (422, 82)\n"
     ]
    }
   ],
   "source": [
    "scores_lbp = []\n",
    "for radius in tqdm(range(1, 11)):\n",
    "    X_tmp = create_lbp_features(radius, 8*radius, test_feature=False)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_tmp)\n",
    "    reg = range(1, 51)\n",
    "    score = []\n",
    "    for c in reg:\n",
    "        svm = SVC(C=c, kernel=pykernels.Tanimoto())\n",
    "        score.append(np.mean(cross_val_score(svm, X_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    print(f\"Rayon {radius} : Best score {np.max(score)} - C {np.argmax(score)+1} | Size of X {X_scaled.shape}\")\n",
    "    scores_lbp.append(np.max(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41819ba",
   "metadata": {},
   "source": [
    "Le meilleur score est atteint pour un rayon de 7, d'où la création de la feature suivante pour la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f140d7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((422, 58), (207, 58))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbp = create_lbp_features(7, 56, test_feature=False)\n",
    "lbp_test = create_lbp_features(7, 56, test_feature=True)\n",
    "lbp.shape, lbp_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89480028",
   "metadata": {},
   "source": [
    "### Scale-invariant feature transform (SIFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937cbcc4",
   "metadata": {},
   "source": [
    "Les descripteurs SIFT sont plus souvent utilisés pour l'identification que pour de la classification. Ils semblaient cependant particulièrement dans le contexte de classification, car il s'agit d'une feature invariante d'échelle. L'utilisation des descripteurs pour de la classification n'est pas immédiate, il convient de créer un `bag of visual words` avec les descripteurs SIFT en amont."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7200c7",
   "metadata": {},
   "source": [
    "<u>Principe </u>: On récupère les descripteurs SIFT de l'ensemble des images (train + test). Chaque keypoint SIFT est décrit par un descripteur de taille 128. On clusterise ensuite ces descripteurs pour trouver les `k` keypoints les plus représentatifs des images. Les descripteurs de chaque image sont ensuite comparés aux `k` descripteurs représentatifs, et un histogramme est constitué pour chaque image (on compte le nombre de fois où un keypoint appartenant au cluster `i` est présent dans l'image). Cela génère donc une feature de taille `k` pour chaque image, qui peut être utilisée dans notre tâche de classification. Cette technique est appelée \"Bag of Visual Words\" dans les différents articles y faisant référence. <br>\n",
    "Un critère très important pour la génération des features SIFT est donc la taille `k` du nombre de clusters à générer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a447157c",
   "metadata": {},
   "source": [
    "<u>Première étape </u>: extraction des keypoints et descripteurs SIFT de l'ensemble des images (Train + Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d5b9c08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3a0dd15fee42fab3a75e83d5a3304c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b18da7fec043c6991a9d4fd0a55347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "# Certaines images sont de dimension 700x456 : je les resize toutes pour ne pas avoir de problème de dimension\n",
    "images = [np.array(Image.open(f).convert('L').resize((700,460))) for f in files_train]\n",
    "images = np.stack(images, axis=0)\n",
    "# Certaines images sont de dimension 700x456 : je les resize toutes pour ne pas avoir de problème de dimension\n",
    "images_test = [np.array(Image.open(f).convert('L').resize((700,460))) for f in files_test]\n",
    "images_test = np.stack(images_test, axis=0)\n",
    "sift_feat = []\n",
    "for im in tqdm(images):\n",
    "    sift_feat.append(sift.detectAndCompute(im, None)[1])\n",
    "for im in tqdm(images_test):\n",
    "    sift_feat.append(sift.detectAndCompute(im, None)[1])\n",
    "sift_feat = np.vstack(sift_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b8c270f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225354, 128)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sift_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7c462",
   "metadata": {},
   "source": [
    "2 225 354 keypoints ont donc été trouvés parmi les 629 images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95954ace",
   "metadata": {},
   "source": [
    "<u>Deuxième étape </u>: clustering des keypoints SIFT extraits, et décompte du nombre de keypoints représentatif dans chaque image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ff3876af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sift_feature(k, sift_feat, images, images_test):\n",
    "    \"\"\" Fonction utilisée pour créer les features SIFT\n",
    "    Args:\n",
    "        k (int) : nombre de cluster / taille des features générées pour chaque image\n",
    "        sift_feat (numpy array nb_total_keypoints x 128) : contient l'ensemble des keypoints SIFT de l'ensemble des images\n",
    "        images (numpy array 422x3x460x700) : array contenant l'ensemble des images de Train\n",
    "        images_test (numpy array 207x3x460x700) : array contenant l'ensemble des images de Test\n",
    "    Return:\n",
    "        ∅ : la génération des features étant très longue, elles ont été enregistrées en local pour pouvoir être\n",
    "        réutilisées plus facilement\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    # 20 initialisations random de KMeans, parmi laquelle la meilleure est gardée\n",
    "    # Cette étape est assez longue, mais la création du cluster est l'étape la plus cruciale de cette méthode\n",
    "    kmeans = KMeans(n_clusters=k, init=\"random\", n_init=20)\n",
    "    kmeans.fit(sift_feat)\n",
    "    \n",
    "    X_tmp = []\n",
    "    for im in images:\n",
    "        # Extraction des descripteurs de chaque image\n",
    "        des = sift.detectAndCompute(im, None)[1]\n",
    "        # Création d'un histogramme vide\n",
    "        histo = np.zeros(k)\n",
    "        for d in des:\n",
    "            # Pour chaque descripteur, association au cluster le plus proche\n",
    "            idx = kmeans.predict(d.reshape(1, -1))\n",
    "            histo[idx] += 1\n",
    "        X_tmp.append(histo)\n",
    "    X_tmp = np.vstack(X_tmp)\n",
    "    \n",
    "    X_tmp_test = []\n",
    "    for im in images_test:\n",
    "        des = sift.detectAndCompute(im, None)[1]\n",
    "        histo = np.zeros(k)\n",
    "        for d in des:\n",
    "            idx = kmeans.predict(d.reshape(1, -1))\n",
    "            histo[idx] += 1\n",
    "        X_tmp_test.append(histo)\n",
    "    X_tmp_test = np.vstack(X_tmp_test)\n",
    "    \n",
    "    np.save(f\"sift_embedding_{k}.npy\", X_tmp)\n",
    "    np.save(f\"sift_embedding_test_{k}.npy\", X_tmp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1519deb",
   "metadata": {},
   "source": [
    "L'étape de clustering via K-Means étant assez longue (clustering de plus de 2 000 000 de keypoints), elle a été réalisée en amont de ce rapport, et les embeddings sauvegardés en local au format `npy`. Des embeddings de dimension variant entre 150 et 650 ont été générés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d0114523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f10c63975d04fdf896326591627dd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de clusters 150 : Best score 0.7823833880190718 - C 7\n",
      "Nombre de clusters 200 : Best score 0.7837624873148378 - C 10\n",
      "Nombre de clusters 250 : Best score 0.7651353073762261 - C 5\n",
      "Nombre de clusters 300 : Best score 0.7858054758829331 - C 7\n",
      "Nombre de clusters 350 : Best score 0.7575363985887491 - C 7\n",
      "Nombre de clusters 400 : Best score 0.7588900178643768 - C 5\n",
      "Nombre de clusters 450 : Best score 0.779959694863541 - C 3\n",
      "Nombre de clusters 500 : Best score 0.7525695320032926 - C 6\n",
      "Nombre de clusters 550 : Best score 0.7726663288739081 - C 10\n",
      "Nombre de clusters 600 : Best score 0.7497361889455907 - C 8\n",
      "Nombre de clusters 650 : Best score 0.7559814077976472 - C 4\n"
     ]
    }
   ],
   "source": [
    "scores_sift = []\n",
    "for k in tqdm([150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650]):\n",
    "    X_tmp = np.load(f\"sift_embedding_{k}.npy\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_tmp)\n",
    "    reg = range(1, 51)\n",
    "    score = []\n",
    "    for c in reg:\n",
    "        svm = SVC(C=c, kernel=pykernels.Tanimoto())\n",
    "        score.append(np.mean(cross_val_score(svm, X_scaled, y_train, cv=16, scoring=\"f1_weighted\")))\n",
    "    print(f\"Nombre de clusters {k} : Best score {np.max(score)} - C {np.argmax(score)+1}\")\n",
    "    scores_sift.append(np.max(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047bfcb0",
   "metadata": {},
   "source": [
    "Le meilleur score est obtenu pour k=300. Ce sont donc les embeddings SIFT de taille 300 qui ont été conservés pour la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f7e82d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((422, 300), (207, 300))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sift = np.load(\"sift_embedding_300.npy\")\n",
    "sift_test = np.load(\"sift_embedding_test_300.npy\")\n",
    "sift.shape, sift_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd26ab5d",
   "metadata": {},
   "source": [
    "## Optimisation de la combinaison des features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84195d3",
   "metadata": {},
   "source": [
    "Pour cette ultime étape, les modèles ne sont plus testés sur 16-folds, mais avec `Leave-One-Out`. La méthode est beaucoup plus calculatoire, mais permet d'obtenir des résultats plus robustes, c'est pourquoi je ne l'ai employé qu'à partir de cette étape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "54409895",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "# Concaténation de toutes les features précédemment extraites\n",
    "X = np.concatenate([pftas, chan_stats, hu, haralick, histo13, lbp, sift], axis=1)\n",
    "X_test = np.concatenate([pftas_test, chan_stats_test, hu_test, haralick_test, histo13_test, lbp_test, sift_test],\n",
    "                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "139a5814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((422, 2764), (207, 2764))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "95482890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7383f56db1db49f38d51ab614a114fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 0.9170616113744076 - C 4\n"
     ]
    }
   ],
   "source": [
    "reg = range(1, 31)\n",
    "score = []\n",
    "for c in tqdm(reg):\n",
    "    svm = SVC(C=c, kernel=pykernels.Tanimoto())\n",
    "    f1 = []\n",
    "    for i, (train_index, test_index) in enumerate(loo.split(X_scaled)):\n",
    "        svm.fit(X_scaled[train_index], y_train[train_index])\n",
    "        y_pred = svm.predict(X_scaled[test_index])\n",
    "        f1.append(f1_score(y_train[test_index], y_pred, average=\"weighted\"))\n",
    "    score.append(np.mean(f1))\n",
    "print(f\"Best score {np.max(score)} - C {np.argmax(score)+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "aa671ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=4, kernel=pykernels.Tanimoto())\n",
    "svm.fit(X_scaled, y_train)\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "df_pred = pd.concat([pd.Series(np.arange(1,208)), pd.Series(y_pred)], axis=1)\n",
    "df_pred.to_csv('pred_full_features.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ae409",
   "metadata": {},
   "source": [
    "**Le score obtenu avec cette soumission est de  0.794713651235**.<br>\n",
    "On remarque que le nombre de features utilisé est relativement important (2764). Utiliser PCA sur cette représentation des données pour réduire la dimension serait drastique (l'implémentation de scitkit-learn de PCA autoriserait l'utilisation maximale de 422 features...). Un test d'ablation de features a donc été favorisé pour voir s'il était possible d'améliorer le score en enlevant une ou plusieurs features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac42099",
   "metadata": {},
   "source": [
    "<u>Test d'ablations de features</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "98d0332b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc3db9f8e4b4efe8ba37c04e6719d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2709f8cab0a4ce6afda0e55c31d5baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature removed PFTAS : Best score 0.919431279620853 - C 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5d40f3dd604a5dbd00c603eea6e259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature removed Channel statistics : Best score 0.9170616113744076 - C 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665dc0de61e44ad09d49d06bdd5bfbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature removed Hu Moments : Best score 0.9146919431279621 - C 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53495ae37fda455aafb2ec1015a51fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature removed Haralick : Best score 0.9146919431279621 - C 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59b94ff30e44246b5f552a8f10563df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature removed Histogramme : Best score 0.933649289099526 - C 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f90f975804c4634925b4e00f3f4e23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature removed LBP : Best score 0.9218009478672986 - C 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76320f8ff3ff4e99b2ec4b5b3f048ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature removed SIFT : Best score 0.919431279620853 - C 7\n"
     ]
    }
   ],
   "source": [
    "features = [pftas, chan_stats, hu, haralick, histo13, lbp, sift]\n",
    "feature_names = [\"PFTAS\", \"Channel statistics\", \"Hu Moments\", \"Haralick\", \"Histogramme\", \"LBP\", \"SIFT\"]\n",
    "for feat in tqdm(range(len(features))):\n",
    "    list_feat = copy.deepcopy(features)\n",
    "    # Supprime la feature feat de la liste des features avant concaténation\n",
    "    del list_feat[feat]\n",
    "    X = np.concatenate(list_feat, axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    reg = range(1, 31)\n",
    "    score = []\n",
    "    for c in tqdm(reg):\n",
    "        svm = SVC(C=c, kernel=pykernels.Tanimoto())\n",
    "        f1 = []\n",
    "        for i, (train_index, test_index) in enumerate(loo.split(X_scaled)):\n",
    "            svm.fit(X_scaled[train_index], y_train[train_index])\n",
    "            y_pred = svm.predict(X_scaled[test_index])\n",
    "            f1.append(f1_score(y_train[test_index], y_pred, average=\"weighted\"))\n",
    "        score.append(np.mean(f1))\n",
    "    print(f\"Feature removed {feature_names[feat]} : Best score {np.max(score)} - C {np.argmax(score)+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0e05c",
   "metadata": {},
   "source": [
    "De manière surprenante, il semblerait qu'en enlevant les features générées via histogramme de couleur, le score global soit amélioré ! J'ai donc recrée une soumission après avoir enlevée les features d'histogramme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8fa86e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((422, 567), (207, 567))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate([pftas, chan_stats, hu, haralick, lbp, sift], axis=1)\n",
    "X_test = np.concatenate([pftas_test, chan_stats_test, hu_test, haralick_test, lbp_test, sift_test],\n",
    "                        axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ccf3caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=3, kernel=pykernels.Tanimoto())\n",
    "svm.fit(X_scaled, y_train)\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "df_pred = pd.concat([pd.Series(np.arange(1,208)), pd.Series(y_pred)], axis=1)\n",
    "df_pred.to_csv('pred_ablation.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6f0673",
   "metadata": {},
   "source": [
    "**Le score obtenu avec cette soumission est de 0.770335965359**, soit 2 points de moins que précédemment. <br>\n",
    "La suppression des features d'histogramme semble avoir abouti à un overfitting du modèle. Retirer entièrement ces features ne semble donc pas pertinent. En revanche, **les features d'histogramme comptent pour 2197 features / 2764**. Peut-être est-il possible de réduire le nombre de bins utilisé ? Le nombre de bins avait été estimé en utilisant uniquement les features d'histogramme. Après combinaison avec d'autres features, il est probablement possible d'utiliser moins de bins pour réduire la dimension et d'obtenir un meilleur score final. <br><br>\n",
    "\n",
    "<u>Optimisation du nombre de bins d'histogramme conjointement aux autres features</u> (range de recherche entre 10 et 15 bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3b53d224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2814962a536413c8d6c80d66ada8bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions X (422, 1567)\n",
      "Bins 10 : Best score 0.9218009478672986 - C 4\n",
      "Dimensions X (422, 1898)\n",
      "Bins 11 : Best score 0.9241706161137441 - C 6\n",
      "Dimensions X (422, 2295)\n",
      "Bins 12 : Best score 0.9170616113744076 - C 4\n",
      "Dimensions X (422, 2764)\n",
      "Bins 13 : Best score 0.9170616113744076 - C 4\n",
      "Dimensions X (422, 3311)\n",
      "Bins 14 : Best score 0.9218009478672986 - C 4\n",
      "Dimensions X (422, 3942)\n",
      "Bins 15 : Best score 0.9218009478672986 - C 4\n"
     ]
    }
   ],
   "source": [
    "for bins in tqdm([10, 11, 12, 13, 14, 15]):\n",
    "    histo = create_histo_features(bins, test_feature=False)\n",
    "    histo_test = create_histo_features(bins, test_feature=True)\n",
    "    X = np.concatenate([pftas, chan_stats, hu, haralick, histo, lbp, sift], axis=1)\n",
    "    X_test = np.concatenate([pftas_test, chan_stats_test, hu_test, haralick_test, histo_test, lbp_test, sift_test],\n",
    "                        axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(f\"Dimensions X {X_scaled.shape}\")\n",
    "    reg = range(1, 11)\n",
    "    score = []\n",
    "    for c in reg:\n",
    "        svm = SVC(C=c, kernel=pykernels.Tanimoto())\n",
    "        f1 = []\n",
    "        for i, (train_index, test_index) in enumerate(loo.split(X_scaled)):\n",
    "            svm.fit(X_scaled[train_index], y_train[train_index])\n",
    "            y_pred = svm.predict(X_scaled[test_index])\n",
    "            f1.append(f1_score(y_train[test_index], y_pred, average=\"weighted\"))\n",
    "        score.append(np.mean(f1))\n",
    "    print(f\"Bins {bins} : Best score {np.max(score)} - C {np.argmax(score)+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3ae28e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo11 = create_histo_features(11, test_feature=False)\n",
    "histo11_test = create_histo_features(11, test_feature=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b9899",
   "metadata": {},
   "source": [
    "Il semblerait qu'utiliser seulement 11 bins permette d'augmenter le score global de classification. <br>\n",
    "Peut-être est-il également possible d'optimiser le nombre de features LBP créées?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "973695fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594dac4a1c5c4568b8abf24411e79964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions X (422, 1858)\n",
      "Radius=2 : Best score 0.9146919431279621 - C 4\n",
      "Dimensions X (422, 1866)\n",
      "Radius=3 : Best score 0.9146919431279621 - C 4\n",
      "Dimensions X (422, 1874)\n",
      "Radius=4 : Best score 0.919431279620853 - C 6\n",
      "Dimensions X (422, 1882)\n",
      "Radius=5 : Best score 0.9170616113744076 - C 3\n",
      "Dimensions X (422, 1890)\n",
      "Radius=6 : Best score 0.9218009478672986 - C 3\n",
      "Dimensions X (422, 1898)\n",
      "Radius=7 : Best score 0.9241706161137441 - C 6\n",
      "Dimensions X (422, 1906)\n",
      "Radius=8 : Best score 0.9265402843601895 - C 7\n",
      "Dimensions X (422, 1914)\n",
      "Radius=9 : Best score 0.9265402843601895 - C 6\n",
      "Dimensions X (422, 1922)\n",
      "Radius=10 : Best score 0.9265402843601895 - C 6\n",
      "Dimensions X (422, 1930)\n",
      "Radius=11 : Best score 0.9241706161137441 - C 5\n"
     ]
    }
   ],
   "source": [
    "for radius in tqdm(range(2,12)):\n",
    "    lbp = create_lbp_features(radius, 8*radius, test_feature=False)\n",
    "    lbp_test = create_lbp_features(radius, 8*radius, test_feature=True)\n",
    "    X = np.concatenate([pftas, chan_stats, hu, haralick, histo11, lbp, sift], axis=1)\n",
    "    X_test = np.concatenate([pftas_test, chan_stats_test, hu_test, haralick_test, histo11_test, lbp_test, sift_test],\n",
    "                        axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(f\"Dimensions X {X_scaled.shape}\")\n",
    "    reg = range(1, 11)\n",
    "    score = []\n",
    "    for c in reg:\n",
    "        svm = SVC(C=c, kernel=pykernels.Tanimoto())\n",
    "        f1 = []\n",
    "        for i, (train_index, test_index) in enumerate(loo.split(X_scaled)):\n",
    "            svm.fit(X_scaled[train_index], y_train[train_index])\n",
    "            y_pred = svm.predict(X_scaled[test_index])\n",
    "            f1.append(f1_score(y_train[test_index], y_pred, average=\"weighted\"))\n",
    "        score.append(np.mean(f1))\n",
    "    print(f\"Radius={radius} : Best score {np.max(score)} - C {np.argmax(score)+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7d6d6",
   "metadata": {},
   "source": [
    "Utiliser un rayon de 9 pixels pour la feature de LBP semble améliorer légèrement le score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5bcb6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp = create_lbp_features(9, 8*9, test_feature=False)\n",
    "lbp_test = create_lbp_features(9, 8*9, test_feature=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "40e6cdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((422, 1914), (207, 1914))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate([pftas, chan_stats, hu, haralick, histo11, lbp, sift], axis=1)\n",
    "X_test = np.concatenate([pftas_test, chan_stats_test, hu_test, haralick_test, histo11_test, lbp_test, sift_test],\n",
    "                        axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2ec8a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=6, kernel=pykernels.Tanimoto())\n",
    "svm.fit(X_scaled, y_train)\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "df_pred = pd.concat([pd.Series(np.arange(1,208)), pd.Series(y_pred)], axis=1)\n",
    "df_pred.to_csv('pred_ultime.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780c122",
   "metadata": {},
   "source": [
    "**Le score obtenu avec cette dernière soumission est de 0.802604153216**. <br>\n",
    "Il semble difficile d'optimiser davantage ce score avec cette méthode sans overfitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576281f8",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285dda2c",
   "metadata": {},
   "source": [
    "Pour obtenir un F1-score optimal de **0.802604153216**, les paramètres suivants ont donc été utilisés :\n",
    "* Classifieur **SVM avec kernel Tanimoto**, paramètre de régularisation **C=6**\n",
    "* 7 feature extractors\n",
    "  1) Parameter-Free Threshold Adjacency Statistics\n",
    "  2) Statistiques des canaux de couleur (moyenne, écart-type, asymétrie, kurtosis)\n",
    "  3) Hu Moments\n",
    "  4) Features de texture Haralick (distance=2, moyenne Point-to-Point et 14 features calculées)\n",
    "  5) Histogramme de couleurs avec 11 bins\n",
    "  6) Local Binary Patterning, avec un rayon de 9 pixels et 72 points\n",
    "  7) Descripteurs SIFT, clusterisés avec 300 centroides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3348c65e",
   "metadata": {},
   "source": [
    "<u>Autres méthodes testées amenant à un 0.76 < F1-Score < 0.79  </u>:\n",
    "* PCA (~35 composantes) avec features histogramme + Haralick + PFTAS\n",
    "* 7 features avec kernel de Cauchy et optimisation du paramètre `s` (variance $\\sigma$)\n",
    "* Classifieur Deep Learning avec 4 couche de convolutions et quelques couches linéaires, appliqué sur des patchs d'images (patchs de taille 115 x 100 px, soit 28 patchs par image de taille 460 x 700 px), suivi d'un hard vote sur les 28 patchs d'image pour identifier la classe de l'image complète (similaire à un vote dans une méthode d'ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fc661",
   "metadata": {},
   "source": [
    "<u>Pistes potentielles d'améliorations </u>:\n",
    "* Utilisation de classifieurs plus complexes (XGBoost, méthodes d'ensemble incluant des SVM avec des kernels différents), avec GridSearchCV pour rechercher les paramètres optimaux -> de très longs temps de calcul en perspective\n",
    "* Optimisation d'un classifieur avec CNN plus profond que celui testé, appliqué à des patchs d'images -> nécessite l'accès à des GPUs pour obtenir des résultats dans un temps raisonnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0afcbf",
   "metadata": {},
   "source": [
    "# Annexe - Code complet pour générer les meilleurs prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54377124",
   "metadata": {},
   "source": [
    "Il est déconseillé de lancer le code tel quel, la génération des features - en particulier SIFT- étant assez longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454fce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mahotas\n",
    "from skimage.feature import local_binary_pattern\n",
    "# A installer depuis https://github.com/gmum/pykernels.git\n",
    "import pykernels\n",
    "\n",
    "\n",
    "# -------- Récupération des images et labels d'entraînement --------\n",
    "class_mapping = {\"F\":1, \"DC\":2, \"PC\":3, \"PT\":4, \"MC\":5, \"LC\":6, \"A\":7, \"TA\":8}\n",
    "# Liste contenant le nom des fichiers de Train\n",
    "files_train = [f\"data-challenge/Train/{f}\" for f in os.listdir(path=\"data-challenge/Train/\")]\n",
    "# Liste contenant le nom des fichiers de Test\n",
    "files_test = [f\"data-challenge/Test/SOB_{i}.png\" for i in range(1, 208)]\n",
    "y_train = np.array([int(class_mapping[f.split(\"_\")[2].split(\"-\")[0]]) for f in files_train])\n",
    "\n",
    "\n",
    "# -------- 1) Extraction features PFTAS --------\n",
    "pftas = np.array([mahotas.features.pftas(np.array(Image.open(f))) for f in files_train])\n",
    "pftas_test = np.array([mahotas.features.pftas(np.array(Image.open(f))) for f in files_test])\n",
    "\n",
    "\n",
    "# -------- 2) Extraction features statistiques de couleurs --------\n",
    "chan_stats = np.array([np.concatenate([np.mean(Image.open(f), axis=(0,1)),\n",
    "                                       np.std(Image.open(f), axis=(0,1)),\n",
    "                                       skew(Image.open(f), axis=(0,1)),\n",
    "                                       kurtosis(Image.open(f), axis=(0,1))]) for f in files_train])\n",
    "chan_stats_test = np.array([np.concatenate([np.mean(Image.open(f), axis=(0,1)),\n",
    "                                       np.std(Image.open(f), axis=(0,1)),\n",
    "                                       skew(Image.open(f), axis=(0,1)),\n",
    "                                       kurtosis(Image.open(f), axis=(0,1))]) for f in files_test])\n",
    "\n",
    "\n",
    "# -------- 3) Extraction features Hu moments --------\n",
    "moments = [cv2.moments(np.array(Image.open(f).convert('L'))) for f in files_train]\n",
    "moments_test = [cv2.moments(np.array(Image.open(f).convert('L'))) for f in files_test]\n",
    "hu = np.array([cv2.HuMoments(m).T for m in moments])[:,0,:]\n",
    "hu_test = np.array([cv2.HuMoments(m).T for m in moments_test])[:,0,:]\n",
    "\n",
    "\n",
    "# -------- 4) Extraction features Haralick --------\n",
    "haralick = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean_ptp=True,\n",
    "                                         compute_14th_feature=True, distance=2) for f in files_train])\n",
    "haralick_test = np.array([mahotas.features.haralick(np.array(Image.open(f)), return_mean_ptp=True,\n",
    "                                         compute_14th_feature=True, distance=2) for f in files_test])\n",
    "\n",
    "\n",
    "# -------- 5) Extraction features Histogrammes --------\n",
    "def create_histo_features(bins, test_feature=False):\n",
    "    \"\"\" Créée des histogrammes de couleurs pour chaque canal HSV des images en input\n",
    "    Args:\n",
    "        bins (int) : nombre de bins (classes) à créer pour chaque canal de l'image HSV\n",
    "        test_feature (Bool): si True, crée des features sur les images de Test, si False créée \n",
    "                                des features sur les images de Train\n",
    "    Output:\n",
    "        X (numpy array) : features extraites (la dimension de sortie dépend du nombre de bins en argument)\n",
    "    \"\"\"\n",
    "    files = files_test if test_feature else files_train\n",
    "    X = []\n",
    "    for f in files:\n",
    "        hsv = cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2HSV)\n",
    "        hist  = cv2.calcHist([hsv], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "        cv2.normalize(hist, hist)\n",
    "        X.append(hist.flatten())\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "histo11 = create_histo_features(11, test_feature=False)\n",
    "histo11_test = create_histo_features(11, test_feature=True)\n",
    "\n",
    "\n",
    "# -------- 6) Extraction features LBP --------\n",
    "# Inspiration : https://cvexplained.wordpress.com/2020/07/22/10-7-local-binary-patterns/\n",
    "def create_lbp_features(radius, points, test_feature=False):\n",
    "    \"\"\" Extrait les features LBP des images en input\n",
    "    Args:\n",
    "        radius (int) : rayon du cercle utilisé pour calculer les features LBP autour d'un pixel\n",
    "        points (int) : nombre de points à garder dans le cercle défini autour du pixel central\n",
    "                        Avec points = radius x 8, tous les points sont conservés\n",
    "        test_feature (Bool): si True, crée des features sur les images de Test, si False créée \n",
    "                                des features sur les images de Train\n",
    "    Output:\n",
    "        X (numpy array) : features extraites (la dimension de sortie dépend du nombre de bins en argument)\n",
    "    \"\"\"\n",
    "    files = files_test if test_feature else files_train\n",
    "    X = []\n",
    "    for f in files:\n",
    "        im = np.array(Image.open(f).convert('L'))\n",
    "        lbp = local_binary_pattern(im, points, radius, method=\"uniform\")\n",
    "        (hist, _) = np.histogram(lbp.ravel(), bins=range(0, points+3), range=(0, points+2))\n",
    "        X.append(hist)\n",
    "    return np.stack(X)\n",
    "\n",
    "lbp = create_lbp_features(9, 8*9, test_feature=False)\n",
    "lbp_test = create_lbp_features(9, 8*9, test_feature=True)\n",
    "\n",
    "\n",
    "# -------- 7) Extraction features SIFT --------\n",
    "# Inspiration : https://www.kaggle.com/code/pierre54/bag-of-words-model-with-sift-descriptors/notebook\n",
    "def create_sift_feature(k, sift_feat, images, images_test):\n",
    "    \"\"\" Fonction utilisée pour créer les features SIFT\n",
    "    Args:\n",
    "        k (int) : nombre de cluster / taille des features générées pour chaque image\n",
    "        sift_feat (numpy array nb_total_keypoints x 128) : contient l'ensemble des keypoints SIFT de l'ensemble des images\n",
    "        images (numpy array 422x3x460x700) : array contenant l'ensemble des images de Train\n",
    "        images_test (numpy array 207x3x460x700) : array contenant l'ensemble des images de Test\n",
    "    Return:\n",
    "        ∅ : la génération des features étant très longue, elles ont été enregistrées en local pour pouvoir être\n",
    "        réutilisées plus facilement\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    # 20 initialisations random de KMeans, parmi laquelle la meilleure est gardée\n",
    "    # Cette étape est assez longue, mais la création du cluster est l'étape la plus cruciale de cette méthode\n",
    "    kmeans = KMeans(n_clusters=k, init=\"random\", n_init=20)\n",
    "    kmeans.fit(sift_feat)\n",
    "    \n",
    "    X_tmp = []\n",
    "    for im in images:\n",
    "        # Extraction des descripteurs de chaque image\n",
    "        des = sift.detectAndCompute(im, None)[1]\n",
    "        # Création d'un histogramme vide\n",
    "        histo = np.zeros(k)\n",
    "        for d in des:\n",
    "            # Pour chaque descripteur, association au cluster le plus proche\n",
    "            idx = kmeans.predict(d.reshape(1, -1))\n",
    "            histo[idx] += 1\n",
    "        X_tmp.append(histo)\n",
    "    X_tmp = np.vstack(X_tmp)\n",
    "    \n",
    "    X_tmp_test = []\n",
    "    for im in images_test:\n",
    "        des = sift.detectAndCompute(im, None)[1]\n",
    "        histo = np.zeros(k)\n",
    "        for d in des:\n",
    "            idx = kmeans.predict(d.reshape(1, -1))\n",
    "            histo[idx] += 1\n",
    "        X_tmp_test.append(histo)\n",
    "    X_tmp_test = np.vstack(X_tmp_test)\n",
    "    \n",
    "    np.save(f\"sift_embedding_{k}.npy\", X_tmp)\n",
    "    np.save(f\"sift_embedding_test_{k}.npy\", X_tmp_test)\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "# Certaines images sont de dimension 700x456 : je les resize toutes pour ne pas avoir de problème de dimension\n",
    "images = [np.array(Image.open(f).convert('L').resize((700,460))) for f in files_train]\n",
    "images = np.stack(images, axis=0)\n",
    "# Certaines images sont de dimension 700x456 : je les resize toutes pour ne pas avoir de problème de dimension\n",
    "images_test = [np.array(Image.open(f).convert('L').resize((700,460))) for f in files_test]\n",
    "images_test = np.stack(images_test, axis=0)\n",
    "\n",
    "# Extraction des descripteurs SIFT de toutes les images\n",
    "sift_feat = []\n",
    "for im in tqdm(images):\n",
    "    sift_feat.append(sift.detectAndCompute(im, None)[1])\n",
    "for im in tqdm(images_test):\n",
    "    sift_feat.append(sift.detectAndCompute(im, None)[1])\n",
    "sift_feat = np.vstack(sift_feat)\n",
    "\n",
    "# Création des features SIFT\n",
    "# Attention, la génération prend beaucoup de temps (cf. n_init=20 pour le K-Means)\n",
    "create_sift_feature(300, sift_feat, images, images_test)\n",
    "sift = np.load(\"sift_embedding_300.npy\")\n",
    "sift_test = np.load(\"sift_embedding_test_300.npy\")\n",
    "\n",
    "\n",
    "# -------- Concaténation des features et fitting du modèle --------\n",
    "X = np.concatenate([pftas, chan_stats, hu, haralick, histo11, lbp, sift], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "svm = SVC(C=6, kernel=pykernels.Tanimoto())\n",
    "svm.fit(X_scaled, y_train)\n",
    "\n",
    "\n",
    "# -------- Génération des prédictions --------\n",
    "X_test = np.concatenate([pftas_test, chan_stats_test, hu_test, haralick_test, histo11_test, lbp_test, sift_test],\n",
    "                        axis=1)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "df_pred = pd.concat([pd.Series(np.arange(1,208)), pd.Series(y_pred)], axis=1)\n",
    "df_pred.to_csv('predictions.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
